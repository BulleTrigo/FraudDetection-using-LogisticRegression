2023-07-21 12:00:45,310:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-21 12:00:45,310:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-21 12:00:45,310:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-21 12:00:45,310:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-21 12:00:46,801:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-07-21 12:02:55,111:INFO:PyCaret ClassificationExperiment
2023-07-21 12:02:55,112:INFO:Logging name: clf-default-name
2023-07-21 12:02:55,112:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-07-21 12:02:55,112:INFO:version 3.0.1
2023-07-21 12:02:55,112:INFO:Initializing setup()
2023-07-21 12:02:55,112:INFO:self.USI: 5cf5
2023-07-21 12:02:55,112:INFO:self._variable_keys: {'memory', '_ml_usecase', 'fold_shuffle_param', 'seed', 'X_test', 'y_test', 'exp_name_log', 'idx', 'USI', 'log_plots_param', '_available_plots', 'gpu_n_jobs_param', 'X', 'is_multiclass', 'X_train', 'n_jobs_param', 'fix_imbalance', 'y', 'logging_param', 'html_param', 'fold_generator', 'target_param', 'fold_groups_param', 'data', 'exp_id', 'y_train', 'pipeline', 'gpu_param'}
2023-07-21 12:02:55,112:INFO:Checking environment
2023-07-21 12:02:55,112:INFO:python_version: 3.10.0
2023-07-21 12:02:55,112:INFO:python_build: ('default', 'Nov 10 2021 13:20:59')
2023-07-21 12:02:55,112:INFO:machine: AMD64
2023-07-21 12:02:55,112:INFO:platform: Windows-10-10.0.22621-SP0
2023-07-21 12:02:55,112:INFO:Memory: svmem(total=16557899776, available=1236443136, percent=92.5, used=15321456640, free=1236443136)
2023-07-21 12:02:55,113:INFO:Physical Core: 8
2023-07-21 12:02:55,113:INFO:Logical Core: 16
2023-07-21 12:02:55,113:INFO:Checking libraries
2023-07-21 12:02:55,113:INFO:System:
2023-07-21 12:02:55,113:INFO:    python: 3.10.0 | packaged by conda-forge | (default, Nov 10 2021, 13:20:59) [MSC v.1916 64 bit (AMD64)]
2023-07-21 12:02:55,113:INFO:executable: c:\Users\Swapn\anaconda3\envs\tf\python.exe
2023-07-21 12:02:55,113:INFO:   machine: Windows-10-10.0.22621-SP0
2023-07-21 12:02:55,113:INFO:PyCaret required dependencies:
2023-07-21 12:02:55,113:INFO:                 pip: 23.2
2023-07-21 12:02:55,113:INFO:          setuptools: 67.7.2
2023-07-21 12:02:55,114:INFO:             pycaret: 3.0.1
2023-07-21 12:02:55,114:INFO:             IPython: 7.34.0
2023-07-21 12:02:55,114:INFO:          ipywidgets: 7.7.5
2023-07-21 12:02:55,114:INFO:                tqdm: 4.65.0
2023-07-21 12:02:55,114:INFO:               numpy: 1.23.0
2023-07-21 12:02:55,114:INFO:              pandas: 1.5.3
2023-07-21 12:02:55,114:INFO:              jinja2: 3.1.2
2023-07-21 12:02:55,114:INFO:               scipy: 1.10.1
2023-07-21 12:02:55,114:INFO:              joblib: 1.2.0
2023-07-21 12:02:55,114:INFO:             sklearn: 1.2.2
2023-07-21 12:02:55,114:INFO:                pyod: 1.0.9
2023-07-21 12:02:55,114:INFO:            imblearn: 0.10.1
2023-07-21 12:02:55,114:INFO:   category_encoders: 2.6.1
2023-07-21 12:02:55,114:INFO:            lightgbm: 3.3.5
2023-07-21 12:02:55,114:INFO:               numba: 0.57.0
2023-07-21 12:02:55,114:INFO:            requests: 2.30.0
2023-07-21 12:02:55,114:INFO:          matplotlib: 3.7.1
2023-07-21 12:02:55,114:INFO:          scikitplot: 0.3.7
2023-07-21 12:02:55,114:INFO:         yellowbrick: 1.5
2023-07-21 12:02:55,114:INFO:              plotly: 5.14.1
2023-07-21 12:02:55,114:INFO:             kaleido: 0.2.1
2023-07-21 12:02:55,114:INFO:         statsmodels: 0.14.0
2023-07-21 12:02:55,114:INFO:              sktime: 0.17.0
2023-07-21 12:02:55,114:INFO:               tbats: 1.1.3
2023-07-21 12:02:55,114:INFO:            pmdarima: 2.0.3
2023-07-21 12:02:55,115:INFO:              psutil: 5.9.0
2023-07-21 12:02:55,115:INFO:PyCaret optional dependencies:
2023-07-21 12:02:57,732:INFO:                shap: 0.42.1
2023-07-21 12:02:57,732:INFO:           interpret: 0.4.2
2023-07-21 12:02:57,732:INFO:                umap: 0.5.3
2023-07-21 12:02:57,732:INFO:    pandas_profiling: 4.3.2
2023-07-21 12:02:57,732:INFO:  explainerdashboard: 0.4.2.2
2023-07-21 12:02:57,732:INFO:             autoviz: 0.1.730
2023-07-21 12:02:57,732:INFO:           fairlearn: 0.7.0
2023-07-21 12:02:57,732:INFO:             xgboost: 1.7.6
2023-07-21 12:02:57,732:INFO:            catboost: 1.2
2023-07-21 12:02:57,732:INFO:              kmodes: 0.12.2
2023-07-21 12:02:57,732:INFO:             mlxtend: 0.22.0
2023-07-21 12:02:57,732:INFO:       statsforecast: 1.5.0
2023-07-21 12:02:57,732:INFO:        tune_sklearn: 0.4.6
2023-07-21 12:02:57,732:INFO:                 ray: 2.6.0
2023-07-21 12:02:57,732:INFO:            hyperopt: 0.2.7
2023-07-21 12:02:57,732:INFO:              optuna: 3.2.0
2023-07-21 12:02:57,732:INFO:               skopt: 0.9.0
2023-07-21 12:02:57,732:INFO:              mlflow: 1.30.1
2023-07-21 12:02:57,732:INFO:              gradio: 3.38.0
2023-07-21 12:02:57,732:INFO:             fastapi: 0.100.0
2023-07-21 12:02:57,732:INFO:             uvicorn: 0.23.1
2023-07-21 12:02:57,732:INFO:              m2cgen: 0.10.0
2023-07-21 12:02:57,732:INFO:           evidently: 0.2.8
2023-07-21 12:02:57,732:INFO:               fugue: 0.8.5
2023-07-21 12:02:57,732:INFO:           streamlit: Not installed
2023-07-21 12:02:57,732:INFO:             prophet: Not installed
2023-07-21 12:02:57,732:INFO:None
2023-07-21 12:02:57,732:INFO:Set up data.
2023-07-21 12:02:59,264:INFO:Set up train/test split.
2023-07-21 12:03:01,949:INFO:Set up index.
2023-07-21 12:03:02,477:INFO:Set up folding strategy.
2023-07-21 12:03:02,477:INFO:Assigning column types.
2023-07-21 12:03:02,725:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-21 12:03:02,777:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-21 12:03:02,779:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-21 12:03:02,819:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-21 12:03:03,207:INFO:Soft dependency imported: catboost: 1.2
2023-07-21 12:03:03,389:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-21 12:03:03,390:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-21 12:03:03,420:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-21 12:03:03,423:INFO:Soft dependency imported: catboost: 1.2
2023-07-21 12:03:03,424:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-21 12:03:03,474:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-21 12:03:03,505:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-21 12:03:03,508:INFO:Soft dependency imported: catboost: 1.2
2023-07-21 12:03:03,558:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-21 12:03:03,588:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-21 12:03:03,591:INFO:Soft dependency imported: catboost: 1.2
2023-07-21 12:03:03,592:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-07-21 12:03:03,671:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-21 12:03:03,675:INFO:Soft dependency imported: catboost: 1.2
2023-07-21 12:03:03,755:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-21 12:03:03,757:INFO:Soft dependency imported: catboost: 1.2
2023-07-21 12:03:03,763:INFO:Preparing preprocessing pipeline...
2023-07-21 12:03:03,824:INFO:Set up simple imputation.
2023-07-21 12:03:04,355:INFO:Set up encoding of categorical features.
2023-07-21 12:03:04,360:INFO:Set up removing outliers.
2023-07-21 12:03:12,938:INFO:Finished creating preprocessing pipeline.
2023-07-21 12:03:12,945:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Swapn\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['amount', 'oldbalanceOrg',
                                             'newbalanceOrig', 'oldbalanceDest',
                                             'newbalanceDest'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy=...
                 TransformerWrapper(exclude=None, include=['type'],
                                    transformer=OneHotEncoder(cols=['type'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=100,
                                                               threshold=0.05)))],
         verbose=False)
2023-07-21 12:03:12,945:INFO:Creating final display dataframe.
2023-07-21 12:08:26,599:INFO:Setup _display_container:                     Description             Value
0                    Session id               100
1                        Target           isFraud
2                   Target type            Binary
3           Original data shape      (4453834, 7)
4        Transformed data shape     (4297950, 11)
5   Transformed train set shape     (2961799, 11)
6    Transformed test set shape     (1336151, 11)
7              Numeric features                 5
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15              Remove outliers              True
16           Outliers threshold              0.05
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              5cf5
2023-07-21 12:08:26,696:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-21 12:08:26,699:INFO:Soft dependency imported: catboost: 1.2
2023-07-21 12:08:26,778:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-21 12:08:26,780:INFO:Soft dependency imported: catboost: 1.2
2023-07-21 12:08:26,782:INFO:setup() successfully completed in 331.67s...............
2023-07-21 12:08:26,804:INFO:Initializing compare_models()
2023-07-21 12:08:26,805:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265372DFD00>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000265372DFD00>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-21 12:08:26,805:INFO:Checking exceptions
2023-07-21 12:08:27,445:INFO:Preparing display monitor
2023-07-21 12:08:27,476:INFO:Initializing Logistic Regression
2023-07-21 12:08:27,476:INFO:Total runtime is 0.0 minutes
2023-07-21 12:08:27,480:INFO:SubProcess create_model() called ==================================
2023-07-21 12:08:27,481:INFO:Initializing create_model()
2023-07-21 12:08:27,482:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265372DFD00>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002648AECC340>, model_only=True, return_train_score=False, kwargs={})
2023-07-21 12:08:27,482:INFO:Checking exceptions
2023-07-21 12:08:27,482:INFO:Importing libraries
2023-07-21 12:08:27,482:INFO:Copying training dataset
2023-07-21 12:08:29,124:INFO:Defining folds
2023-07-21 12:08:29,124:INFO:Declaring metric variables
2023-07-21 12:08:29,129:INFO:Importing untrained model
2023-07-21 12:08:29,134:INFO:Logistic Regression Imported successfully
2023-07-21 12:08:29,143:INFO:Starting cross validation
2023-07-21 12:08:29,156:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-21 12:09:00,257:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-07-21 12:09:00,320:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-07-21 12:09:01,390:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-07-21 12:09:08,874:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-21 12:09:09,196:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-21 12:09:10,408:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-21 12:09:11,686:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-21 12:09:11,721:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-21 12:09:11,736:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-21 12:09:11,857:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-21 12:09:28,854:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 12:09:29,117:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 12:09:29,780:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 12:09:30,332:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 12:09:30,462:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 12:09:31,494:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 12:09:33,509:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 12:09:33,646:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 12:09:33,767:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 12:09:33,774:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 12:21:47,366:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-21 12:21:47,368:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-21 12:21:47,363:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-21 12:21:48,969:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-21 12:21:49,109:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-21 12:21:49,153:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-21 12:21:49,576:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.40s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-21 12:21:49,618:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-21 12:21:49,771:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-21 12:21:50,414:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-21 12:23:16,273:INFO:Calculating mean and std
2023-07-21 12:23:16,339:INFO:Creating metrics dataframe
2023-07-21 12:23:16,481:INFO:Uploading results into container
2023-07-21 12:23:16,486:INFO:Uploading model into container now
2023-07-21 12:23:16,494:INFO:_master_model_container: 1
2023-07-21 12:23:16,494:INFO:_display_container: 2
2023-07-21 12:23:16,500:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-21 12:23:16,501:INFO:create_model() successfully completed......................................
2023-07-21 12:23:17,644:INFO:SubProcess create_model() end ==================================
2023-07-21 12:23:17,644:INFO:Creating metrics dataframe
2023-07-21 12:23:17,664:INFO:Initializing K Neighbors Classifier
2023-07-21 12:23:17,664:INFO:Total runtime is 14.836470119158427 minutes
2023-07-21 12:23:17,670:INFO:SubProcess create_model() called ==================================
2023-07-21 12:23:17,671:INFO:Initializing create_model()
2023-07-21 12:23:17,671:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265372DFD00>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002648AECC340>, model_only=True, return_train_score=False, kwargs={})
2023-07-21 12:23:17,671:INFO:Checking exceptions
2023-07-21 12:23:17,671:INFO:Importing libraries
2023-07-21 12:23:17,671:INFO:Copying training dataset
2023-07-21 12:23:20,249:INFO:Defining folds
2023-07-21 12:23:20,249:INFO:Declaring metric variables
2023-07-21 12:23:20,254:INFO:Importing untrained model
2023-07-21 12:23:20,259:INFO:K Neighbors Classifier Imported successfully
2023-07-21 12:23:20,267:INFO:Starting cross validation
2023-07-21 12:23:20,285:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-21 12:23:32,673:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-07-21 12:23:32,806:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-07-21 12:23:42,208:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-21 12:23:42,389:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-21 12:24:05,644:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 12:24:05,979:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 12:24:07,458:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 12:24:08,427:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 12:24:10,049:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 12:24:10,467:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 12:24:10,488:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 12:24:10,661:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 12:24:10,961:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 12:24:11,451:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 12:35:11,588:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-21 12:35:12,783:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-21 12:35:14,479:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-21 12:35:16,606:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-21 12:35:16,656:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-21 12:35:16,657:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-21 12:35:16,701:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-21 12:35:16,705:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-21 12:35:17,482:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-21 12:35:17,644:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-21 12:35:47,874:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-21 12:35:49,229:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 12:35:49,390:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 12:35:51,326:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 12:35:51,942:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 12:35:52,725:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 12:35:52,929:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.31s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 12:35:52,963:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.29s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 12:35:53,658:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-21 12:35:53,658:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 12:35:55,294:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-21 12:35:57,265:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-21 12:35:57,276:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-21 12:35:57,328:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-21 12:35:57,339:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-21 12:35:57,434:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-21 12:35:57,630:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-21 12:36:31,345:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-21 12:36:37,916:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 1.40s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-21 12:37:14,583:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-21 12:37:22,217:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 1.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-21 12:37:24,163:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-21 12:37:45,342:INFO:Calculating mean and std
2023-07-21 12:37:45,420:INFO:Creating metrics dataframe
2023-07-21 12:37:45,570:INFO:Uploading results into container
2023-07-21 12:37:45,574:INFO:Uploading model into container now
2023-07-21 12:37:45,586:INFO:_master_model_container: 2
2023-07-21 12:37:45,586:INFO:_display_container: 2
2023-07-21 12:37:45,601:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-07-21 12:37:45,602:INFO:create_model() successfully completed......................................
2023-07-21 12:37:46,337:INFO:SubProcess create_model() end ==================================
2023-07-21 12:37:46,337:INFO:Creating metrics dataframe
2023-07-21 12:37:46,358:INFO:Initializing Naive Bayes
2023-07-21 12:37:46,359:INFO:Total runtime is 29.314705228805543 minutes
2023-07-21 12:37:46,363:INFO:SubProcess create_model() called ==================================
2023-07-21 12:37:46,364:INFO:Initializing create_model()
2023-07-21 12:37:46,364:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265372DFD00>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002648AECC340>, model_only=True, return_train_score=False, kwargs={})
2023-07-21 12:37:46,364:INFO:Checking exceptions
2023-07-21 12:37:46,364:INFO:Importing libraries
2023-07-21 12:37:46,365:INFO:Copying training dataset
2023-07-21 12:37:48,778:INFO:Defining folds
2023-07-21 12:37:48,779:INFO:Declaring metric variables
2023-07-21 12:37:48,784:INFO:Importing untrained model
2023-07-21 12:37:48,788:INFO:Naive Bayes Imported successfully
2023-07-21 12:37:48,798:INFO:Starting cross validation
2023-07-21 12:37:48,814:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-21 12:38:08,728:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-21 12:38:21,781:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 12:38:22,876:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 12:38:23,876:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 12:38:24,170:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 12:38:24,502:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 12:38:24,829:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 12:38:25,196:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 12:38:25,200:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 12:38:25,213:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 12:38:25,380:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 12:48:26,927:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-21 12:48:28,278:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-21 12:48:30,371:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-21 12:48:43,645:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-21 12:48:43,923:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-21 12:48:44,544:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-21 12:48:44,765:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-21 12:48:45,082:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-21 12:48:45,367:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-21 12:48:49,281:INFO:Calculating mean and std
2023-07-21 12:48:49,311:INFO:Creating metrics dataframe
2023-07-21 12:48:49,409:INFO:Uploading results into container
2023-07-21 12:48:49,412:INFO:Uploading model into container now
2023-07-21 12:48:49,416:INFO:_master_model_container: 3
2023-07-21 12:48:49,416:INFO:_display_container: 2
2023-07-21 12:48:49,420:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-21 12:48:49,420:INFO:create_model() successfully completed......................................
2023-07-21 12:48:49,894:INFO:SubProcess create_model() end ==================================
2023-07-21 12:48:49,894:INFO:Creating metrics dataframe
2023-07-21 12:48:49,915:INFO:Initializing Decision Tree Classifier
2023-07-21 12:48:49,915:INFO:Total runtime is 40.373994815349576 minutes
2023-07-21 12:48:49,919:INFO:SubProcess create_model() called ==================================
2023-07-21 12:48:49,920:INFO:Initializing create_model()
2023-07-21 12:48:49,920:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265372DFD00>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002648AECC340>, model_only=True, return_train_score=False, kwargs={})
2023-07-21 12:48:49,920:INFO:Checking exceptions
2023-07-21 12:48:49,920:INFO:Importing libraries
2023-07-21 12:48:49,920:INFO:Copying training dataset
2023-07-21 12:48:51,768:INFO:Defining folds
2023-07-21 12:48:51,768:INFO:Declaring metric variables
2023-07-21 12:48:51,773:INFO:Importing untrained model
2023-07-21 12:48:51,778:INFO:Decision Tree Classifier Imported successfully
2023-07-21 12:48:51,789:INFO:Starting cross validation
2023-07-21 12:48:51,809:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-21 12:49:21,490:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 12:49:22,913:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 12:49:23,780:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 12:49:23,857:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 12:49:24,247:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 12:49:24,402:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 12:49:25,323:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 12:49:25,803:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 12:49:25,812:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 12:49:26,009:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 12:59:55,799:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-21 12:59:55,910:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-21 12:59:58,242:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-21 13:00:07,767:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.34s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-21 13:00:08,300:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-21 13:00:08,401:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-21 13:00:08,520:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-21 13:00:08,521:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-21 13:00:09,141:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-21 13:00:09,160:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-07-21 13:00:46,456:INFO:Calculating mean and std
2023-07-21 13:00:46,508:INFO:Creating metrics dataframe
2023-07-21 13:00:46,631:INFO:Uploading results into container
2023-07-21 13:00:46,636:INFO:Uploading model into container now
2023-07-21 13:00:46,642:INFO:_master_model_container: 4
2023-07-21 13:00:46,642:INFO:_display_container: 2
2023-07-21 13:00:46,649:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=100, splitter='best')
2023-07-21 13:00:46,650:INFO:create_model() successfully completed......................................
2023-07-21 13:00:47,263:INFO:SubProcess create_model() end ==================================
2023-07-21 13:00:47,263:INFO:Creating metrics dataframe
2023-07-21 13:00:47,283:INFO:Initializing SVM - Linear Kernel
2023-07-21 13:00:47,283:INFO:Total runtime is 52.33011626799901 minutes
2023-07-21 13:00:47,287:INFO:SubProcess create_model() called ==================================
2023-07-21 13:00:47,288:INFO:Initializing create_model()
2023-07-21 13:00:47,288:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265372DFD00>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002648AECC340>, model_only=True, return_train_score=False, kwargs={})
2023-07-21 13:00:47,288:INFO:Checking exceptions
2023-07-21 13:00:47,288:INFO:Importing libraries
2023-07-21 13:00:47,288:INFO:Copying training dataset
2023-07-21 13:00:50,577:INFO:Defining folds
2023-07-21 13:00:50,578:INFO:Declaring metric variables
2023-07-21 13:00:50,583:INFO:Importing untrained model
2023-07-21 13:00:50,589:INFO:SVM - Linear Kernel Imported successfully
2023-07-21 13:00:50,597:INFO:Starting cross validation
2023-07-21 13:00:50,618:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-21 13:02:08,787:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-21 13:02:09,616:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-21 13:02:13,474:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-21 13:02:19,665:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-21 13:02:20,267:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-21 13:02:23,252:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-21 13:02:24,752:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-21 13:02:34,088:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-21 13:02:37,178:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-21 13:02:51,031:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-21 13:02:51,422:INFO:Calculating mean and std
2023-07-21 13:02:51,424:INFO:Creating metrics dataframe
2023-07-21 13:02:51,482:INFO:Uploading results into container
2023-07-21 13:02:51,482:INFO:Uploading model into container now
2023-07-21 13:02:51,483:INFO:_master_model_container: 5
2023-07-21 13:02:51,483:INFO:_display_container: 2
2023-07-21 13:02:51,484:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=100, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-21 13:02:51,485:INFO:create_model() successfully completed......................................
2023-07-21 13:02:51,624:INFO:SubProcess create_model() end ==================================
2023-07-21 13:02:51,624:INFO:Creating metrics dataframe
2023-07-21 13:02:51,636:INFO:Initializing Ridge Classifier
2023-07-21 13:02:51,636:INFO:Total runtime is 54.40267606973648 minutes
2023-07-21 13:02:51,640:INFO:SubProcess create_model() called ==================================
2023-07-21 13:02:51,641:INFO:Initializing create_model()
2023-07-21 13:02:51,641:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265372DFD00>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002648AECC340>, model_only=True, return_train_score=False, kwargs={})
2023-07-21 13:02:51,641:INFO:Checking exceptions
2023-07-21 13:02:51,641:INFO:Importing libraries
2023-07-21 13:02:51,641:INFO:Copying training dataset
2023-07-21 13:02:53,143:INFO:Defining folds
2023-07-21 13:02:53,143:INFO:Declaring metric variables
2023-07-21 13:02:53,147:INFO:Importing untrained model
2023-07-21 13:02:53,152:INFO:Ridge Classifier Imported successfully
2023-07-21 13:02:53,161:INFO:Starting cross validation
2023-07-21 13:02:53,177:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-21 13:02:58,489:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.93914e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-21 13:02:58,668:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=6.83957e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-21 13:02:58,715:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=6.34317e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-21 13:02:58,743:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=6.68793e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-21 13:02:59,073:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-21 13:02:59,264:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-21 13:02:59,302:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-21 13:02:59,310:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-21 13:03:08,875:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=6.89903e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-21 13:03:09,509:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=6.73098e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-21 13:03:09,515:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=6.24009e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-21 13:03:09,517:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=6.73579e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-21 13:03:09,527:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-21 13:03:09,547:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.04126e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-21 13:03:09,556:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=6.80776e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-21 13:03:10,135:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-21 13:03:10,157:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-21 13:03:10,166:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-21 13:03:10,204:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-21 13:03:10,235:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-21 13:03:10,855:INFO:Calculating mean and std
2023-07-21 13:03:10,856:INFO:Creating metrics dataframe
2023-07-21 13:03:10,915:INFO:Uploading results into container
2023-07-21 13:03:10,916:INFO:Uploading model into container now
2023-07-21 13:03:10,916:INFO:_master_model_container: 6
2023-07-21 13:03:10,917:INFO:_display_container: 2
2023-07-21 13:03:10,917:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=100, solver='auto',
                tol=0.0001)
2023-07-21 13:03:10,917:INFO:create_model() successfully completed......................................
2023-07-21 13:03:11,075:INFO:SubProcess create_model() end ==================================
2023-07-21 13:03:11,075:INFO:Creating metrics dataframe
2023-07-21 13:03:11,087:INFO:Initializing Random Forest Classifier
2023-07-21 13:03:11,088:INFO:Total runtime is 54.72687840064366 minutes
2023-07-21 13:03:11,093:INFO:SubProcess create_model() called ==================================
2023-07-21 13:03:11,094:INFO:Initializing create_model()
2023-07-21 13:03:11,094:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265372DFD00>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002648AECC340>, model_only=True, return_train_score=False, kwargs={})
2023-07-21 13:03:11,094:INFO:Checking exceptions
2023-07-21 13:03:11,094:INFO:Importing libraries
2023-07-21 13:03:11,094:INFO:Copying training dataset
2023-07-21 13:03:12,730:INFO:Defining folds
2023-07-21 13:03:12,730:INFO:Declaring metric variables
2023-07-21 13:03:12,734:INFO:Importing untrained model
2023-07-21 13:03:12,741:INFO:Random Forest Classifier Imported successfully
2023-07-21 13:03:12,750:INFO:Starting cross validation
2023-07-21 13:03:12,766:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-21 13:15:05,236:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 61.27s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 13:15:31,704:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 8.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-21 13:16:00,292:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 48.45s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 13:16:23,982:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-21 13:17:55,126:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 13:17:55,472:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 13:17:55,548:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 13:17:55,589:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 13:17:56,559:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-21 13:17:56,784:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-21 13:18:02,779:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.29s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 13:18:03,615:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.40s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 13:18:04,242:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 13:18:08,215:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 13:18:10,459:INFO:Calculating mean and std
2023-07-21 13:18:10,529:INFO:Creating metrics dataframe
2023-07-21 13:18:10,703:INFO:Uploading results into container
2023-07-21 13:18:10,709:INFO:Uploading model into container now
2023-07-21 13:18:10,719:INFO:_master_model_container: 7
2023-07-21 13:18:10,720:INFO:_display_container: 2
2023-07-21 13:18:10,729:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=100, verbose=0, warm_start=False)
2023-07-21 13:18:10,729:INFO:create_model() successfully completed......................................
2023-07-21 13:18:11,447:INFO:SubProcess create_model() end ==================================
2023-07-21 13:18:11,448:INFO:Creating metrics dataframe
2023-07-21 13:18:11,468:INFO:Initializing Quadratic Discriminant Analysis
2023-07-21 13:18:11,468:INFO:Total runtime is 69.73320710659027 minutes
2023-07-21 13:18:11,473:INFO:SubProcess create_model() called ==================================
2023-07-21 13:18:11,474:INFO:Initializing create_model()
2023-07-21 13:18:11,474:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265372DFD00>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002648AECC340>, model_only=True, return_train_score=False, kwargs={})
2023-07-21 13:18:11,474:INFO:Checking exceptions
2023-07-21 13:18:11,474:INFO:Importing libraries
2023-07-21 13:18:11,474:INFO:Copying training dataset
2023-07-21 13:18:14,349:INFO:Defining folds
2023-07-21 13:18:14,349:INFO:Declaring metric variables
2023-07-21 13:18:14,355:INFO:Importing untrained model
2023-07-21 13:18:14,361:INFO:Quadratic Discriminant Analysis Imported successfully
2023-07-21 13:18:14,370:INFO:Starting cross validation
2023-07-21 13:18:14,396:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-21 13:18:46,986:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-21 13:18:47,319:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-21 13:18:49,169:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-21 13:18:49,214:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-21 13:18:49,262:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-21 13:18:49,561:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-21 13:18:49,662:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-21 13:18:49,797:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-21 13:18:49,806:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-21 13:18:49,861:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-21 13:18:50,093:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 13:18:50,213:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.44s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 13:18:50,536:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 13:18:50,664:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 13:18:51,219:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 13:18:51,220:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 13:18:51,268:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 13:18:51,271:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 13:18:51,377:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 13:18:51,380:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-21 13:18:51,388:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 13:18:51,391:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 13:18:51,404:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 13:18:51,414:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 13:18:51,415:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 13:18:51,435:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 13:18:51,436:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 13:18:51,441:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-21 13:18:51,497:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 13:18:51,544:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-21 13:18:51,561:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-21 13:18:51,595:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-21 13:18:51,630:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 13:18:51,631:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 13:18:51,771:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-21 13:18:51,946:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 13:18:51,948:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 13:18:51,996:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 13:18:51,998:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 13:18:52,088:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 13:18:52,089:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 13:18:52,104:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 13:18:52,105:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 13:18:52,131:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-21 13:18:52,163:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-21 13:18:52,198:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 13:18:52,199:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 13:18:52,252:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-21 13:18:52,290:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-21 13:18:52,293:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-21 13:18:52,334:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-21 13:18:52,375:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 13:18:52,376:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 13:18:52,389:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-21 13:18:52,390:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 13:18:52,391:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 13:18:52,396:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-21 13:18:52,445:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-21 13:18:52,456:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 13:18:52,457:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 13:18:52,556:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-21 13:18:52,569:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-21 13:18:52,583:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-21 13:18:52,609:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-21 13:18:52,614:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 13:18:52,615:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 13:18:52,704:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-21 13:18:52,749:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-21 13:18:53,006:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 13:18:53,006:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 13:18:53,046:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 13:18:53,047:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 13:18:53,121:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-21 13:18:53,159:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-21 13:18:53,182:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 13:18:53,183:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 13:18:53,222:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-21 13:18:53,254:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-21 13:18:53,263:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-21 13:18:53,324:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-21 13:18:54,368:INFO:Calculating mean and std
2023-07-21 13:18:54,401:INFO:Creating metrics dataframe
2023-07-21 13:18:54,572:INFO:Uploading results into container
2023-07-21 13:18:54,576:INFO:Uploading model into container now
2023-07-21 13:18:54,578:INFO:_master_model_container: 8
2023-07-21 13:18:54,578:INFO:_display_container: 2
2023-07-21 13:18:54,581:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-07-21 13:18:54,583:INFO:create_model() successfully completed......................................
2023-07-21 13:18:55,014:INFO:SubProcess create_model() end ==================================
2023-07-21 13:18:55,014:INFO:Creating metrics dataframe
2023-07-21 13:18:55,041:INFO:Initializing Ada Boost Classifier
2023-07-21 13:18:55,042:INFO:Total runtime is 70.45943470398585 minutes
2023-07-21 13:18:55,047:INFO:SubProcess create_model() called ==================================
2023-07-21 13:18:55,047:INFO:Initializing create_model()
2023-07-21 13:18:55,047:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265372DFD00>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002648AECC340>, model_only=True, return_train_score=False, kwargs={})
2023-07-21 13:18:55,047:INFO:Checking exceptions
2023-07-21 13:18:55,048:INFO:Importing libraries
2023-07-21 13:18:55,048:INFO:Copying training dataset
2023-07-21 13:18:56,975:INFO:Defining folds
2023-07-21 13:18:56,975:INFO:Declaring metric variables
2023-07-21 13:18:56,979:INFO:Importing untrained model
2023-07-21 13:18:56,983:INFO:Ada Boost Classifier Imported successfully
2023-07-21 13:18:56,992:INFO:Starting cross validation
2023-07-21 13:18:57,009:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-21 13:25:39,548:INFO:Calculating mean and std
2023-07-21 13:25:39,550:INFO:Creating metrics dataframe
2023-07-21 13:25:39,620:INFO:Uploading results into container
2023-07-21 13:25:39,620:INFO:Uploading model into container now
2023-07-21 13:25:39,621:INFO:_master_model_container: 9
2023-07-21 13:25:39,621:INFO:_display_container: 2
2023-07-21 13:25:39,621:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=100)
2023-07-21 13:25:39,621:INFO:create_model() successfully completed......................................
2023-07-21 13:25:39,769:INFO:SubProcess create_model() end ==================================
2023-07-21 13:25:39,769:INFO:Creating metrics dataframe
2023-07-21 13:25:39,782:INFO:Initializing Gradient Boosting Classifier
2023-07-21 13:25:39,782:INFO:Total runtime is 77.20509843826294 minutes
2023-07-21 13:25:39,786:INFO:SubProcess create_model() called ==================================
2023-07-21 13:25:39,787:INFO:Initializing create_model()
2023-07-21 13:25:39,787:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265372DFD00>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002648AECC340>, model_only=True, return_train_score=False, kwargs={})
2023-07-21 13:25:39,787:INFO:Checking exceptions
2023-07-21 13:25:39,787:INFO:Importing libraries
2023-07-21 13:25:39,787:INFO:Copying training dataset
2023-07-21 13:25:41,431:INFO:Defining folds
2023-07-21 13:25:41,431:INFO:Declaring metric variables
2023-07-21 13:25:41,436:INFO:Importing untrained model
2023-07-21 13:25:41,441:INFO:Gradient Boosting Classifier Imported successfully
2023-07-21 13:25:41,450:INFO:Starting cross validation
2023-07-21 13:25:41,464:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-21 13:54:48,040:INFO:Calculating mean and std
2023-07-21 13:54:48,046:INFO:Creating metrics dataframe
2023-07-21 13:54:48,147:INFO:Uploading results into container
2023-07-21 13:54:48,150:INFO:Uploading model into container now
2023-07-21 13:54:48,153:INFO:_master_model_container: 10
2023-07-21 13:54:48,153:INFO:_display_container: 2
2023-07-21 13:54:48,156:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=100, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-21 13:54:48,156:INFO:create_model() successfully completed......................................
2023-07-21 13:54:48,467:INFO:SubProcess create_model() end ==================================
2023-07-21 13:54:48,468:INFO:Creating metrics dataframe
2023-07-21 13:54:48,485:INFO:Initializing Linear Discriminant Analysis
2023-07-21 13:54:48,485:INFO:Total runtime is 106.35015513499577 minutes
2023-07-21 13:54:48,489:INFO:SubProcess create_model() called ==================================
2023-07-21 13:54:48,489:INFO:Initializing create_model()
2023-07-21 13:54:48,490:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265372DFD00>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002648AECC340>, model_only=True, return_train_score=False, kwargs={})
2023-07-21 13:54:48,490:INFO:Checking exceptions
2023-07-21 13:54:48,490:INFO:Importing libraries
2023-07-21 13:54:48,490:INFO:Copying training dataset
2023-07-21 13:54:50,065:INFO:Defining folds
2023-07-21 13:54:50,065:INFO:Declaring metric variables
2023-07-21 13:54:50,071:INFO:Importing untrained model
2023-07-21 13:54:50,075:INFO:Linear Discriminant Analysis Imported successfully
2023-07-21 13:54:50,084:INFO:Starting cross validation
2023-07-21 13:54:50,098:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-21 13:55:10,106:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 13:55:11,370:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 13:55:15,906:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 13:55:16,287:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 13:55:18,215:INFO:Calculating mean and std
2023-07-21 13:55:18,246:INFO:Creating metrics dataframe
2023-07-21 13:55:18,348:INFO:Uploading results into container
2023-07-21 13:55:18,350:INFO:Uploading model into container now
2023-07-21 13:55:18,352:INFO:_master_model_container: 11
2023-07-21 13:55:18,352:INFO:_display_container: 2
2023-07-21 13:55:18,355:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-07-21 13:55:18,355:INFO:create_model() successfully completed......................................
2023-07-21 13:55:18,864:INFO:SubProcess create_model() end ==================================
2023-07-21 13:55:18,865:INFO:Creating metrics dataframe
2023-07-21 13:55:18,896:INFO:Initializing Extra Trees Classifier
2023-07-21 13:55:18,896:INFO:Total runtime is 106.85700956185659 minutes
2023-07-21 13:55:18,905:INFO:SubProcess create_model() called ==================================
2023-07-21 13:55:18,905:INFO:Initializing create_model()
2023-07-21 13:55:18,905:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265372DFD00>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002648AECC340>, model_only=True, return_train_score=False, kwargs={})
2023-07-21 13:55:18,905:INFO:Checking exceptions
2023-07-21 13:55:18,906:INFO:Importing libraries
2023-07-21 13:55:18,906:INFO:Copying training dataset
2023-07-21 13:55:21,867:INFO:Defining folds
2023-07-21 13:55:21,867:INFO:Declaring metric variables
2023-07-21 13:55:21,875:INFO:Importing untrained model
2023-07-21 13:55:21,882:INFO:Extra Trees Classifier Imported successfully
2023-07-21 13:55:21,896:INFO:Starting cross validation
2023-07-21 13:55:21,914:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-21 13:58:03,594:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 14:00:59,031:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 7.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 14:01:15,247:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 5.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-21 14:01:15,257:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 11.46s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 14:01:18,257:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 8.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 14:01:21,890:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 5.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 14:01:22,628:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-21 14:01:27,216:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-21 14:01:29,143:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-21 14:01:43,777:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 4.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 14:01:49,684:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-21 14:02:07,277:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 14:03:21,337:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 14:03:21,598:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 14:03:30,539:INFO:Calculating mean and std
2023-07-21 14:03:30,563:INFO:Creating metrics dataframe
2023-07-21 14:03:30,695:INFO:Uploading results into container
2023-07-21 14:03:30,698:INFO:Uploading model into container now
2023-07-21 14:03:30,703:INFO:_master_model_container: 12
2023-07-21 14:03:30,703:INFO:_display_container: 2
2023-07-21 14:03:30,709:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=100, verbose=0, warm_start=False)
2023-07-21 14:03:30,709:INFO:create_model() successfully completed......................................
2023-07-21 14:03:31,267:INFO:SubProcess create_model() end ==================================
2023-07-21 14:03:31,268:INFO:Creating metrics dataframe
2023-07-21 14:03:31,287:INFO:Initializing Extreme Gradient Boosting
2023-07-21 14:03:31,288:INFO:Total runtime is 115.0635449330012 minutes
2023-07-21 14:03:31,294:INFO:SubProcess create_model() called ==================================
2023-07-21 14:03:31,295:INFO:Initializing create_model()
2023-07-21 14:03:31,295:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265372DFD00>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002648AECC340>, model_only=True, return_train_score=False, kwargs={})
2023-07-21 14:03:31,295:INFO:Checking exceptions
2023-07-21 14:03:31,296:INFO:Importing libraries
2023-07-21 14:03:31,296:INFO:Copying training dataset
2023-07-21 14:03:33,205:INFO:Defining folds
2023-07-21 14:03:33,205:INFO:Declaring metric variables
2023-07-21 14:03:33,210:INFO:Importing untrained model
2023-07-21 14:03:33,216:INFO:Extreme Gradient Boosting Imported successfully
2023-07-21 14:03:33,225:INFO:Starting cross validation
2023-07-21 14:03:33,247:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-21 14:18:19,422:INFO:Calculating mean and std
2023-07-21 14:18:19,423:INFO:Creating metrics dataframe
2023-07-21 14:18:19,511:INFO:Uploading results into container
2023-07-21 14:18:19,512:INFO:Uploading model into container now
2023-07-21 14:18:19,512:INFO:_master_model_container: 13
2023-07-21 14:18:19,512:INFO:_display_container: 2
2023-07-21 14:18:19,513:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-07-21 14:18:19,513:INFO:create_model() successfully completed......................................
2023-07-21 14:18:19,656:INFO:SubProcess create_model() end ==================================
2023-07-21 14:18:19,656:INFO:Creating metrics dataframe
2023-07-21 14:18:19,672:INFO:Initializing Light Gradient Boosting Machine
2023-07-21 14:18:19,672:INFO:Total runtime is 129.86994132995605 minutes
2023-07-21 14:18:19,676:INFO:SubProcess create_model() called ==================================
2023-07-21 14:18:19,676:INFO:Initializing create_model()
2023-07-21 14:18:19,676:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265372DFD00>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002648AECC340>, model_only=True, return_train_score=False, kwargs={})
2023-07-21 14:18:19,676:INFO:Checking exceptions
2023-07-21 14:18:19,676:INFO:Importing libraries
2023-07-21 14:18:19,677:INFO:Copying training dataset
2023-07-21 14:18:21,086:INFO:Defining folds
2023-07-21 14:18:21,086:INFO:Declaring metric variables
2023-07-21 14:18:21,091:INFO:Importing untrained model
2023-07-21 14:18:21,096:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-21 14:18:21,104:INFO:Starting cross validation
2023-07-21 14:18:21,116:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-21 14:19:21,121:INFO:Calculating mean and std
2023-07-21 14:19:21,123:INFO:Creating metrics dataframe
2023-07-21 14:19:21,218:INFO:Uploading results into container
2023-07-21 14:19:21,219:INFO:Uploading model into container now
2023-07-21 14:19:21,220:INFO:_master_model_container: 14
2023-07-21 14:19:21,220:INFO:_display_container: 2
2023-07-21 14:19:21,220:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=100, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-07-21 14:19:21,220:INFO:create_model() successfully completed......................................
2023-07-21 14:19:21,373:INFO:SubProcess create_model() end ==================================
2023-07-21 14:19:21,374:INFO:Creating metrics dataframe
2023-07-21 14:19:21,389:INFO:Initializing CatBoost Classifier
2023-07-21 14:19:21,389:INFO:Total runtime is 130.8985571185748 minutes
2023-07-21 14:19:21,394:INFO:SubProcess create_model() called ==================================
2023-07-21 14:19:21,395:INFO:Initializing create_model()
2023-07-21 14:19:21,395:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265372DFD00>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002648AECC340>, model_only=True, return_train_score=False, kwargs={})
2023-07-21 14:19:21,395:INFO:Checking exceptions
2023-07-21 14:19:21,395:INFO:Importing libraries
2023-07-21 14:19:21,395:INFO:Copying training dataset
2023-07-21 14:19:22,801:INFO:Defining folds
2023-07-21 14:19:22,802:INFO:Declaring metric variables
2023-07-21 14:19:22,806:INFO:Importing untrained model
2023-07-21 14:19:22,819:INFO:CatBoost Classifier Imported successfully
2023-07-21 14:19:22,826:INFO:Starting cross validation
2023-07-21 14:19:22,837:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-21 14:47:49,704:INFO:Calculating mean and std
2023-07-21 14:47:49,707:INFO:Creating metrics dataframe
2023-07-21 14:47:49,810:INFO:Uploading results into container
2023-07-21 14:47:49,812:INFO:Uploading model into container now
2023-07-21 14:47:49,812:INFO:_master_model_container: 15
2023-07-21 14:47:49,813:INFO:_display_container: 2
2023-07-21 14:47:49,813:INFO:<catboost.core.CatBoostClassifier object at 0x000002653FF5E380>
2023-07-21 14:47:49,813:INFO:create_model() successfully completed......................................
2023-07-21 14:47:50,004:INFO:SubProcess create_model() end ==================================
2023-07-21 14:47:50,005:INFO:Creating metrics dataframe
2023-07-21 14:47:50,021:INFO:Initializing Dummy Classifier
2023-07-21 14:47:50,022:INFO:Total runtime is 159.3757760445277 minutes
2023-07-21 14:47:50,026:INFO:SubProcess create_model() called ==================================
2023-07-21 14:47:50,027:INFO:Initializing create_model()
2023-07-21 14:47:50,028:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265372DFD00>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002648AECC340>, model_only=True, return_train_score=False, kwargs={})
2023-07-21 14:47:50,028:INFO:Checking exceptions
2023-07-21 14:47:50,028:INFO:Importing libraries
2023-07-21 14:47:50,028:INFO:Copying training dataset
2023-07-21 14:47:51,506:INFO:Defining folds
2023-07-21 14:47:51,506:INFO:Declaring metric variables
2023-07-21 14:47:51,511:INFO:Importing untrained model
2023-07-21 14:47:51,516:INFO:Dummy Classifier Imported successfully
2023-07-21 14:47:51,524:INFO:Starting cross validation
2023-07-21 14:47:51,536:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-21 14:47:58,247:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-21 14:47:58,262:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-21 14:47:58,541:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-21 14:47:58,626:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-21 14:47:58,692:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-21 14:47:58,697:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-21 14:47:58,733:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-21 14:47:58,752:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-21 14:48:03,393:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-21 14:48:03,396:WARNING:c:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-21 14:48:03,783:INFO:Calculating mean and std
2023-07-21 14:48:03,784:INFO:Creating metrics dataframe
2023-07-21 14:48:03,874:INFO:Uploading results into container
2023-07-21 14:48:03,875:INFO:Uploading model into container now
2023-07-21 14:48:03,875:INFO:_master_model_container: 16
2023-07-21 14:48:03,875:INFO:_display_container: 2
2023-07-21 14:48:03,876:INFO:DummyClassifier(constant=None, random_state=100, strategy='prior')
2023-07-21 14:48:03,876:INFO:create_model() successfully completed......................................
2023-07-21 14:48:04,007:INFO:SubProcess create_model() end ==================================
2023-07-21 14:48:04,008:INFO:Creating metrics dataframe
2023-07-21 14:48:04,037:INFO:Initializing create_model()
2023-07-21 14:48:04,037:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265372DFD00>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-21 14:48:04,037:INFO:Checking exceptions
2023-07-21 14:48:04,045:INFO:Importing libraries
2023-07-21 14:48:04,045:INFO:Copying training dataset
2023-07-21 14:48:05,528:INFO:Defining folds
2023-07-21 14:48:05,528:INFO:Declaring metric variables
2023-07-21 14:48:05,528:INFO:Importing untrained model
2023-07-21 14:48:05,528:INFO:Declaring custom model
2023-07-21 14:48:05,529:INFO:Logistic Regression Imported successfully
2023-07-21 14:48:05,539:INFO:Cross validation set to False
2023-07-21 14:48:05,540:INFO:Fitting Model
2023-07-21 14:50:46,403:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-21 14:50:46,403:INFO:create_model() successfully completed......................................
2023-07-21 14:50:46,562:INFO:Initializing create_model()
2023-07-21 14:50:46,563:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265372DFD00>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-21 14:50:46,564:INFO:Checking exceptions
2023-07-21 14:50:46,566:INFO:Importing libraries
2023-07-21 14:50:46,567:INFO:Copying training dataset
2023-07-21 14:50:47,886:INFO:Defining folds
2023-07-21 14:50:47,887:INFO:Declaring metric variables
2023-07-21 14:50:47,887:INFO:Importing untrained model
2023-07-21 14:50:47,887:INFO:Declaring custom model
2023-07-21 14:50:47,888:INFO:Extreme Gradient Boosting Imported successfully
2023-07-21 14:50:47,898:INFO:Cross validation set to False
2023-07-21 14:50:47,898:INFO:Fitting Model
2023-07-21 14:52:45,718:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-07-21 14:52:45,719:INFO:create_model() successfully completed......................................
2023-07-21 14:52:45,858:INFO:Initializing create_model()
2023-07-21 14:52:45,858:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265372DFD00>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=100, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-21 14:52:45,859:INFO:Checking exceptions
2023-07-21 14:52:45,862:INFO:Importing libraries
2023-07-21 14:52:45,862:INFO:Copying training dataset
2023-07-21 14:52:47,145:INFO:Defining folds
2023-07-21 14:52:47,146:INFO:Declaring metric variables
2023-07-21 14:52:47,146:INFO:Importing untrained model
2023-07-21 14:52:47,146:INFO:Declaring custom model
2023-07-21 14:52:47,147:INFO:Random Forest Classifier Imported successfully
2023-07-21 14:52:47,156:INFO:Cross validation set to False
2023-07-21 14:52:47,156:INFO:Fitting Model
2023-07-21 14:54:26,490:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=100, verbose=0, warm_start=False)
2023-07-21 14:54:26,490:INFO:create_model() successfully completed......................................
2023-07-21 14:54:26,659:INFO:_master_model_container: 16
2023-07-21 14:54:26,660:INFO:_display_container: 2
2023-07-21 14:54:26,662:INFO:[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=100, verbose=0, warm_start=False)]
2023-07-21 14:54:26,662:INFO:compare_models() successfully completed......................................
2023-07-21 15:50:08,948:INFO:Initializing create_model()
2023-07-21 15:50:08,948:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265372DFD00>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-21 15:50:08,948:INFO:Checking exceptions
2023-07-21 15:50:08,971:INFO:Importing libraries
2023-07-21 15:50:08,971:INFO:Copying training dataset
2023-07-21 15:50:10,547:INFO:Defining folds
2023-07-21 15:50:10,547:INFO:Declaring metric variables
2023-07-21 15:50:10,551:INFO:Importing untrained model
2023-07-21 15:50:10,556:INFO:Logistic Regression Imported successfully
2023-07-21 15:50:10,564:INFO:Starting cross validation
2023-07-21 15:50:10,574:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-21 15:51:46,744:INFO:Calculating mean and std
2023-07-21 15:51:46,746:INFO:Creating metrics dataframe
2023-07-21 15:51:46,755:INFO:Finalizing model
2023-07-21 15:51:48,383:INFO:Uploading results into container
2023-07-21 15:51:48,385:INFO:Uploading model into container now
2023-07-21 15:51:48,401:INFO:_master_model_container: 17
2023-07-21 15:51:48,401:INFO:_display_container: 3
2023-07-21 15:51:48,401:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-21 15:51:48,402:INFO:create_model() successfully completed......................................
2023-07-21 15:51:48,666:INFO:Initializing plot_model()
2023-07-21 15:51:48,667:INFO:plot_model(plot=learning, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265372DFD00>, system=True)
2023-07-21 15:51:48,667:INFO:Checking exceptions
2023-07-21 15:51:49,236:INFO:Preloading libraries
2023-07-21 15:51:49,237:INFO:Copying training dataset
2023-07-21 15:51:49,237:INFO:Plot type: learning
2023-07-21 15:54:26,551:INFO:Fitting Model
2023-07-21 16:11:48,048:INFO:Visual Rendered Successfully
2023-07-21 16:11:48,231:INFO:plot_model() successfully completed......................................
2023-07-21 16:11:48,282:INFO:Initializing plot_model()
2023-07-21 16:11:48,282:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265372DFD00>, system=True)
2023-07-21 16:11:48,282:INFO:Checking exceptions
2023-07-21 16:11:48,767:INFO:Preloading libraries
2023-07-21 16:11:48,767:INFO:Copying training dataset
2023-07-21 16:11:48,767:INFO:Plot type: auc
2023-07-21 16:11:52,332:INFO:Fitting Model
2023-07-21 16:11:52,398:INFO:Scoring test/hold-out set
2023-07-21 16:11:53,677:INFO:Visual Rendered Successfully
2023-07-21 16:11:53,841:INFO:plot_model() successfully completed......................................
2023-07-21 16:11:53,881:INFO:Initializing plot_model()
2023-07-21 16:11:53,881:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs={'percent': True}, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265372DFD00>, system=True)
2023-07-21 16:11:53,881:INFO:Checking exceptions
2023-07-21 16:11:54,372:INFO:Preloading libraries
2023-07-21 16:11:54,372:INFO:Copying training dataset
2023-07-21 16:11:54,372:INFO:Plot type: confusion_matrix
2023-07-21 16:11:57,947:INFO:Fitting Model
2023-07-21 16:11:57,980:INFO:Scoring test/hold-out set
2023-07-21 16:11:58,411:INFO:Visual Rendered Successfully
2023-07-21 16:11:58,564:INFO:plot_model() successfully completed......................................
2023-07-21 16:11:58,607:INFO:Initializing plot_model()
2023-07-21 16:11:58,608:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265372DFD00>, system=True)
2023-07-21 16:11:58,608:INFO:Checking exceptions
2023-07-21 16:11:59,082:INFO:Preloading libraries
2023-07-21 16:11:59,083:INFO:Copying training dataset
2023-07-21 16:11:59,083:INFO:Plot type: error
2023-07-21 16:12:02,853:INFO:Fitting Model
2023-07-21 16:12:02,887:INFO:Scoring test/hold-out set
2023-07-21 16:12:03,439:INFO:Visual Rendered Successfully
2023-07-21 16:12:03,594:INFO:plot_model() successfully completed......................................
2023-07-21 16:12:03,632:INFO:Initializing plot_model()
2023-07-21 16:12:03,632:INFO:plot_model(plot=class_report, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265372DFD00>, system=True)
2023-07-21 16:12:03,632:INFO:Checking exceptions
2023-07-21 16:12:04,102:INFO:Preloading libraries
2023-07-21 16:12:04,102:INFO:Copying training dataset
2023-07-21 16:12:04,102:INFO:Plot type: class_report
2023-07-21 16:12:07,919:INFO:Fitting Model
2023-07-21 16:12:07,951:INFO:Scoring test/hold-out set
2023-07-21 16:12:08,741:INFO:Visual Rendered Successfully
2023-07-21 16:12:08,901:INFO:plot_model() successfully completed......................................
2023-07-21 16:12:08,926:INFO:Initializing plot_model()
2023-07-21 16:12:08,926:INFO:plot_model(plot=boundary, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265372DFD00>, system=True)
2023-07-21 16:12:08,926:INFO:Checking exceptions
2023-07-21 16:12:09,404:INFO:Preloading libraries
2023-07-21 16:12:09,404:INFO:Copying training dataset
2023-07-21 16:12:09,404:INFO:Plot type: boundary
2023-07-21 16:12:11,323:INFO:Fitting StandardScaler()
2023-07-21 16:12:12,158:INFO:Fitting PCA()
2023-07-21 16:12:21,705:INFO:Fitting Model
2023-07-21 16:13:05,611:INFO:Visual Rendered Successfully
2023-07-21 16:13:05,833:INFO:plot_model() successfully completed......................................
2023-07-21 16:13:05,871:INFO:Initializing interpret_model()
2023-07-21 16:13:05,872:INFO:interpret_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265372DFD00>)
2023-07-21 16:13:05,872:INFO:Checking exceptions
2023-07-21 16:13:05,873:INFO:Soft dependency imported: shap: 0.42.1
2023-07-21 16:16:11,201:INFO:Initializing evaluate_model()
2023-07-21 16:16:11,201:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265372DFD00>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-07-21 16:16:11,661:INFO:Initializing plot_model()
2023-07-21 16:16:11,661:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265372DFD00>, system=True)
2023-07-21 16:16:11,661:INFO:Checking exceptions
2023-07-21 16:16:12,181:INFO:Preloading libraries
2023-07-21 16:16:12,181:INFO:Copying training dataset
2023-07-21 16:16:12,181:INFO:Plot type: pipeline
2023-07-21 16:16:12,475:INFO:Visual Rendered Successfully
2023-07-21 16:16:12,695:INFO:plot_model() successfully completed......................................
2023-07-21 16:16:20,270:INFO:Initializing plot_model()
2023-07-21 16:16:20,270:INFO:plot_model(plot=parameter, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265372DFD00>, system=True)
2023-07-21 16:16:20,270:INFO:Checking exceptions
2023-07-21 16:16:20,677:INFO:Preloading libraries
2023-07-21 16:16:20,677:INFO:Copying training dataset
2023-07-21 16:16:20,678:INFO:Plot type: parameter
2023-07-21 16:16:20,681:INFO:Visual Rendered Successfully
2023-07-21 16:16:20,836:INFO:plot_model() successfully completed......................................
2023-07-21 16:16:21,271:INFO:Initializing plot_model()
2023-07-21 16:16:21,272:INFO:plot_model(plot=manifold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000265372DFD00>, system=True)
2023-07-21 16:16:21,272:INFO:Checking exceptions
2023-07-21 16:16:21,732:INFO:Preloading libraries
2023-07-21 16:16:21,732:INFO:Copying training dataset
2023-07-21 16:16:21,732:INFO:Plot type: manifold
2023-07-21 16:16:25,057:INFO:Fitting & Transforming Model
2023-07-21 16:23:17,715:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-21 16:23:17,716:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-21 16:23:17,716:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-21 16:23:17,716:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-21 16:23:18,771:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-07-21 16:23:21,678:INFO:PyCaret ClassificationExperiment
2023-07-21 16:23:21,678:INFO:Logging name: clf-default-name
2023-07-21 16:23:21,678:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-07-21 16:23:21,678:INFO:version 3.0.1
2023-07-21 16:23:21,678:INFO:Initializing setup()
2023-07-21 16:23:21,678:INFO:self.USI: 1766
2023-07-21 16:23:21,679:INFO:self._variable_keys: {'log_plots_param', 'y_test', 'gpu_param', 'y_train', 'pipeline', 'X_train', 'html_param', 'X_test', 'exp_id', 'fold_shuffle_param', 'fix_imbalance', 'fold_groups_param', 'fold_generator', 'USI', 'y', 'is_multiclass', '_available_plots', 'exp_name_log', 'idx', '_ml_usecase', 'n_jobs_param', 'target_param', 'memory', 'X', 'seed', 'data', 'gpu_n_jobs_param', 'logging_param'}
2023-07-21 16:23:21,679:INFO:Checking environment
2023-07-21 16:23:21,679:INFO:python_version: 3.10.0
2023-07-21 16:23:21,679:INFO:python_build: ('default', 'Nov 10 2021 13:20:59')
2023-07-21 16:23:21,679:INFO:machine: AMD64
2023-07-21 16:23:21,679:INFO:platform: Windows-10-10.0.22621-SP0
2023-07-21 16:23:21,679:INFO:Memory: svmem(total=16557899776, available=5432201216, percent=67.2, used=11125698560, free=5432201216)
2023-07-21 16:23:21,679:INFO:Physical Core: 8
2023-07-21 16:23:21,679:INFO:Logical Core: 16
2023-07-21 16:23:21,679:INFO:Checking libraries
2023-07-21 16:23:21,679:INFO:System:
2023-07-21 16:23:21,679:INFO:    python: 3.10.0 | packaged by conda-forge | (default, Nov 10 2021, 13:20:59) [MSC v.1916 64 bit (AMD64)]
2023-07-21 16:23:21,679:INFO:executable: C:\Users\Swapn\anaconda3\envs\tf\python.exe
2023-07-21 16:23:21,679:INFO:   machine: Windows-10-10.0.22621-SP0
2023-07-21 16:23:21,679:INFO:PyCaret required dependencies:
2023-07-21 16:23:21,679:INFO:                 pip: 23.2
2023-07-21 16:23:21,679:INFO:          setuptools: 67.7.2
2023-07-21 16:23:21,679:INFO:             pycaret: 3.0.1
2023-07-21 16:23:21,679:INFO:             IPython: 7.34.0
2023-07-21 16:23:21,679:INFO:          ipywidgets: 7.7.5
2023-07-21 16:23:21,680:INFO:                tqdm: 4.65.0
2023-07-21 16:23:21,680:INFO:               numpy: 1.23.0
2023-07-21 16:23:21,680:INFO:              pandas: 1.5.3
2023-07-21 16:23:21,680:INFO:              jinja2: 3.1.2
2023-07-21 16:23:21,680:INFO:               scipy: 1.10.1
2023-07-21 16:23:21,680:INFO:              joblib: 1.2.0
2023-07-21 16:23:21,680:INFO:             sklearn: 1.2.2
2023-07-21 16:23:21,680:INFO:                pyod: 1.0.9
2023-07-21 16:23:21,680:INFO:            imblearn: 0.10.1
2023-07-21 16:23:21,680:INFO:   category_encoders: 2.6.1
2023-07-21 16:23:21,680:INFO:            lightgbm: 3.3.5
2023-07-21 16:23:21,680:INFO:               numba: 0.57.0
2023-07-21 16:23:21,680:INFO:            requests: 2.30.0
2023-07-21 16:23:21,680:INFO:          matplotlib: 3.7.1
2023-07-21 16:23:21,680:INFO:          scikitplot: 0.3.7
2023-07-21 16:23:21,680:INFO:         yellowbrick: 1.5
2023-07-21 16:23:21,680:INFO:              plotly: 5.14.1
2023-07-21 16:23:21,680:INFO:             kaleido: 0.2.1
2023-07-21 16:23:21,680:INFO:         statsmodels: 0.14.0
2023-07-21 16:23:21,680:INFO:              sktime: 0.17.0
2023-07-21 16:23:21,680:INFO:               tbats: 1.1.3
2023-07-21 16:23:21,680:INFO:            pmdarima: 2.0.3
2023-07-21 16:23:21,680:INFO:              psutil: 5.9.0
2023-07-21 16:23:21,681:INFO:PyCaret optional dependencies:
2023-07-21 16:23:23,290:INFO:                shap: 0.42.1
2023-07-21 16:23:23,290:INFO:           interpret: 0.4.2
2023-07-21 16:23:23,290:INFO:                umap: 0.5.3
2023-07-21 16:23:23,290:INFO:    pandas_profiling: 4.3.2
2023-07-21 16:23:23,290:INFO:  explainerdashboard: 0.4.2.2
2023-07-21 16:23:23,290:INFO:             autoviz: 0.1.730
2023-07-21 16:23:23,291:INFO:           fairlearn: 0.7.0
2023-07-21 16:23:23,291:INFO:             xgboost: 1.7.6
2023-07-21 16:23:23,291:INFO:            catboost: 1.2
2023-07-21 16:23:23,291:INFO:              kmodes: 0.12.2
2023-07-21 16:23:23,291:INFO:             mlxtend: 0.22.0
2023-07-21 16:23:23,291:INFO:       statsforecast: 1.5.0
2023-07-21 16:23:23,291:INFO:        tune_sklearn: 0.4.6
2023-07-21 16:23:23,291:INFO:                 ray: 2.6.0
2023-07-21 16:23:23,291:INFO:            hyperopt: 0.2.7
2023-07-21 16:23:23,291:INFO:              optuna: 3.2.0
2023-07-21 16:23:23,291:INFO:               skopt: 0.9.0
2023-07-21 16:23:23,291:INFO:              mlflow: 1.30.1
2023-07-21 16:23:23,291:INFO:              gradio: 3.38.0
2023-07-21 16:23:23,291:INFO:             fastapi: 0.100.0
2023-07-21 16:23:23,291:INFO:             uvicorn: 0.23.1
2023-07-21 16:23:23,291:INFO:              m2cgen: 0.10.0
2023-07-21 16:23:23,291:INFO:           evidently: 0.2.8
2023-07-21 16:23:23,291:INFO:               fugue: 0.8.5
2023-07-21 16:23:23,291:INFO:           streamlit: Not installed
2023-07-21 16:23:23,291:INFO:             prophet: Not installed
2023-07-21 16:23:23,291:INFO:None
2023-07-21 16:23:23,291:INFO:Set up data.
2023-07-21 16:23:24,400:INFO:Set up train/test split.
2023-07-21 16:23:26,281:INFO:Set up index.
2023-07-21 16:23:26,689:INFO:Set up folding strategy.
2023-07-21 16:23:26,689:INFO:Assigning column types.
2023-07-21 16:23:26,869:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-21 16:23:26,917:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-21 16:23:26,919:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-21 16:23:26,957:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-21 16:23:27,310:INFO:Soft dependency imported: catboost: 1.2
2023-07-21 16:23:27,467:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-21 16:23:27,468:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-21 16:23:27,497:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-21 16:23:27,500:INFO:Soft dependency imported: catboost: 1.2
2023-07-21 16:23:27,501:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-21 16:23:27,549:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-21 16:23:27,579:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-21 16:23:27,582:INFO:Soft dependency imported: catboost: 1.2
2023-07-21 16:23:27,633:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-21 16:23:27,663:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-21 16:23:27,666:INFO:Soft dependency imported: catboost: 1.2
2023-07-21 16:23:27,667:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-07-21 16:23:27,746:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-21 16:23:27,748:INFO:Soft dependency imported: catboost: 1.2
2023-07-21 16:23:27,828:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-21 16:23:27,831:INFO:Soft dependency imported: catboost: 1.2
2023-07-21 16:23:27,834:INFO:Preparing preprocessing pipeline...
2023-07-21 16:23:27,888:INFO:Set up simple imputation.
2023-07-21 16:23:28,323:INFO:Set up encoding of categorical features.
2023-07-21 16:23:28,328:INFO:Set up removing outliers.
2023-07-21 16:23:30,053:INFO:Finished creating preprocessing pipeline.
2023-07-21 16:23:30,062:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Swapn\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['amount', 'oldbalanceOrg',
                                             'newbalanceOrig', 'oldbalanceDest',
                                             'newbalanceDest'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy=...
                 TransformerWrapper(exclude=None, include=['type'],
                                    transformer=OneHotEncoder(cols=['type'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=100,
                                                               threshold=0.05)))],
         verbose=False)
2023-07-21 16:23:30,062:INFO:Creating final display dataframe.
2023-07-21 16:23:34,894:INFO:Setup _display_container:                     Description             Value
0                    Session id               100
1                        Target           isFraud
2                   Target type            Binary
3           Original data shape      (4453834, 7)
4        Transformed data shape     (4297950, 11)
5   Transformed train set shape     (2961799, 11)
6    Transformed test set shape     (1336151, 11)
7              Numeric features                 5
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15              Remove outliers              True
16           Outliers threshold              0.05
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              1766
2023-07-21 16:23:34,982:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-21 16:23:34,985:INFO:Soft dependency imported: catboost: 1.2
2023-07-21 16:23:35,064:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-21 16:23:35,067:INFO:Soft dependency imported: catboost: 1.2
2023-07-21 16:23:35,068:INFO:setup() successfully completed in 13.52s...............
2023-07-21 16:23:35,086:INFO:Initializing compare_models()
2023-07-21 16:23:35,087:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FF57EA6F50>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001FF57EA6F50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-21 16:23:35,087:INFO:Checking exceptions
2023-07-21 16:23:35,555:INFO:Preparing display monitor
2023-07-21 16:23:35,581:INFO:Initializing Logistic Regression
2023-07-21 16:23:35,582:INFO:Total runtime is 1.6844272613525392e-05 minutes
2023-07-21 16:23:35,586:INFO:SubProcess create_model() called ==================================
2023-07-21 16:23:35,586:INFO:Initializing create_model()
2023-07-21 16:23:35,586:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FF57EA6F50>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE93BF49A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-21 16:23:35,586:INFO:Checking exceptions
2023-07-21 16:23:35,587:INFO:Importing libraries
2023-07-21 16:23:35,587:INFO:Copying training dataset
2023-07-21 16:23:36,754:INFO:Defining folds
2023-07-21 16:23:36,755:INFO:Declaring metric variables
2023-07-21 16:23:36,759:INFO:Importing untrained model
2023-07-21 16:23:36,763:INFO:Logistic Regression Imported successfully
2023-07-21 16:23:36,771:INFO:Starting cross validation
2023-07-21 16:23:36,773:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-21 16:23:51,370:INFO:Calculating mean and std
2023-07-21 16:23:51,382:INFO:Creating metrics dataframe
2023-07-21 16:23:51,482:INFO:Uploading results into container
2023-07-21 16:23:51,485:INFO:Uploading model into container now
2023-07-21 16:23:51,488:INFO:_master_model_container: 1
2023-07-21 16:23:51,488:INFO:_display_container: 2
2023-07-21 16:23:51,489:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-21 16:23:51,490:INFO:create_model() successfully completed......................................
2023-07-21 16:23:53,458:INFO:SubProcess create_model() end ==================================
2023-07-21 16:23:53,458:INFO:Creating metrics dataframe
2023-07-21 16:23:53,469:INFO:Initializing K Neighbors Classifier
2023-07-21 16:23:53,469:INFO:Total runtime is 0.2981340169906616 minutes
2023-07-21 16:23:53,473:INFO:SubProcess create_model() called ==================================
2023-07-21 16:23:53,474:INFO:Initializing create_model()
2023-07-21 16:23:53,474:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FF57EA6F50>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE93BF49A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-21 16:23:53,474:INFO:Checking exceptions
2023-07-21 16:23:53,474:INFO:Importing libraries
2023-07-21 16:23:53,475:INFO:Copying training dataset
2023-07-21 16:23:54,694:INFO:Defining folds
2023-07-21 16:23:54,695:INFO:Declaring metric variables
2023-07-21 16:23:54,699:INFO:Importing untrained model
2023-07-21 16:23:54,704:INFO:K Neighbors Classifier Imported successfully
2023-07-21 16:23:54,711:INFO:Starting cross validation
2023-07-21 16:23:54,713:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-21 16:24:46,447:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 16:24:46,605:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 16:24:47,552:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 16:24:47,916:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 16:24:49,986:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 16:25:17,652:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-21 16:25:28,866:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-21 16:25:32,178:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-21 16:25:50,192:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-21 16:25:50,328:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-21 16:26:10,366:INFO:Calculating mean and std
2023-07-21 16:26:10,368:INFO:Creating metrics dataframe
2023-07-21 16:26:10,444:INFO:Uploading results into container
2023-07-21 16:26:10,445:INFO:Uploading model into container now
2023-07-21 16:26:10,445:INFO:_master_model_container: 2
2023-07-21 16:26:10,445:INFO:_display_container: 2
2023-07-21 16:26:10,446:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-07-21 16:26:10,446:INFO:create_model() successfully completed......................................
2023-07-21 16:26:10,575:INFO:SubProcess create_model() end ==================================
2023-07-21 16:26:10,576:INFO:Creating metrics dataframe
2023-07-21 16:26:10,591:INFO:Initializing Naive Bayes
2023-07-21 16:26:10,591:INFO:Total runtime is 2.5835047364234924 minutes
2023-07-21 16:26:10,595:INFO:SubProcess create_model() called ==================================
2023-07-21 16:26:10,596:INFO:Initializing create_model()
2023-07-21 16:26:10,596:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FF57EA6F50>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE93BF49A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-21 16:26:10,596:INFO:Checking exceptions
2023-07-21 16:26:10,596:INFO:Importing libraries
2023-07-21 16:26:10,596:INFO:Copying training dataset
2023-07-21 16:26:11,872:INFO:Defining folds
2023-07-21 16:26:11,873:INFO:Declaring metric variables
2023-07-21 16:26:11,877:INFO:Importing untrained model
2023-07-21 16:26:11,882:INFO:Naive Bayes Imported successfully
2023-07-21 16:26:11,890:INFO:Starting cross validation
2023-07-21 16:26:11,891:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-21 16:26:29,785:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 16:26:30,016:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 16:26:30,309:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 16:26:30,309:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 16:30:04,202:INFO:Calculating mean and std
2023-07-21 16:30:04,204:INFO:Creating metrics dataframe
2023-07-21 16:30:04,271:INFO:Uploading results into container
2023-07-21 16:30:04,272:INFO:Uploading model into container now
2023-07-21 16:30:04,273:INFO:_master_model_container: 3
2023-07-21 16:30:04,273:INFO:_display_container: 2
2023-07-21 16:30:04,273:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-21 16:30:04,273:INFO:create_model() successfully completed......................................
2023-07-21 16:30:04,418:INFO:SubProcess create_model() end ==================================
2023-07-21 16:30:04,418:INFO:Creating metrics dataframe
2023-07-21 16:30:04,428:INFO:Initializing Decision Tree Classifier
2023-07-21 16:30:04,428:INFO:Total runtime is 6.480773528416952 minutes
2023-07-21 16:30:04,432:INFO:SubProcess create_model() called ==================================
2023-07-21 16:30:04,432:INFO:Initializing create_model()
2023-07-21 16:30:04,432:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FF57EA6F50>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE93BF49A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-21 16:30:04,432:INFO:Checking exceptions
2023-07-21 16:30:04,432:INFO:Importing libraries
2023-07-21 16:30:04,432:INFO:Copying training dataset
2023-07-21 16:30:05,592:INFO:Defining folds
2023-07-21 16:30:05,592:INFO:Declaring metric variables
2023-07-21 16:30:05,596:INFO:Importing untrained model
2023-07-21 16:30:05,600:INFO:Decision Tree Classifier Imported successfully
2023-07-21 16:30:05,608:INFO:Starting cross validation
2023-07-21 16:30:05,609:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-21 16:30:24,878:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 16:30:25,112:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 16:30:25,379:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 16:30:25,429:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 16:34:30,168:INFO:Calculating mean and std
2023-07-21 16:34:30,169:INFO:Creating metrics dataframe
2023-07-21 16:34:30,241:INFO:Uploading results into container
2023-07-21 16:34:30,242:INFO:Uploading model into container now
2023-07-21 16:34:30,243:INFO:_master_model_container: 4
2023-07-21 16:34:30,243:INFO:_display_container: 2
2023-07-21 16:34:30,243:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=100, splitter='best')
2023-07-21 16:34:30,243:INFO:create_model() successfully completed......................................
2023-07-21 16:34:30,425:INFO:SubProcess create_model() end ==================================
2023-07-21 16:34:30,425:INFO:Creating metrics dataframe
2023-07-21 16:34:30,439:INFO:Initializing SVM - Linear Kernel
2023-07-21 16:34:30,440:INFO:Total runtime is 10.914308019479115 minutes
2023-07-21 16:34:30,443:INFO:SubProcess create_model() called ==================================
2023-07-21 16:34:30,444:INFO:Initializing create_model()
2023-07-21 16:34:30,444:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FF57EA6F50>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE93BF49A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-21 16:34:30,444:INFO:Checking exceptions
2023-07-21 16:34:30,445:INFO:Importing libraries
2023-07-21 16:34:30,445:INFO:Copying training dataset
2023-07-21 16:34:31,671:INFO:Defining folds
2023-07-21 16:34:31,671:INFO:Declaring metric variables
2023-07-21 16:34:31,675:INFO:Importing untrained model
2023-07-21 16:34:31,680:INFO:SVM - Linear Kernel Imported successfully
2023-07-21 16:34:31,688:INFO:Starting cross validation
2023-07-21 16:34:31,690:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-21 16:35:32,817:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-21 16:35:33,150:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-21 16:35:35,117:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-21 16:35:41,113:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-21 16:35:41,215:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-21 16:35:42,465:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-21 16:35:44,737:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-21 16:35:52,674:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-21 16:35:54,927:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-21 16:36:09,043:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-21 16:36:09,466:INFO:Calculating mean and std
2023-07-21 16:36:09,467:INFO:Creating metrics dataframe
2023-07-21 16:36:09,550:INFO:Uploading results into container
2023-07-21 16:36:09,551:INFO:Uploading model into container now
2023-07-21 16:36:09,551:INFO:_master_model_container: 5
2023-07-21 16:36:09,551:INFO:_display_container: 2
2023-07-21 16:36:09,553:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=100, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-21 16:36:09,553:INFO:create_model() successfully completed......................................
2023-07-21 16:36:09,735:INFO:SubProcess create_model() end ==================================
2023-07-21 16:36:09,735:INFO:Creating metrics dataframe
2023-07-21 16:36:09,758:INFO:Initializing Ridge Classifier
2023-07-21 16:36:09,758:INFO:Total runtime is 12.569619536399841 minutes
2023-07-21 16:36:09,767:INFO:SubProcess create_model() called ==================================
2023-07-21 16:36:09,768:INFO:Initializing create_model()
2023-07-21 16:36:09,768:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FF57EA6F50>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE93BF49A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-21 16:36:09,768:INFO:Checking exceptions
2023-07-21 16:36:09,769:INFO:Importing libraries
2023-07-21 16:36:09,769:INFO:Copying training dataset
2023-07-21 16:36:11,354:INFO:Defining folds
2023-07-21 16:36:11,355:INFO:Declaring metric variables
2023-07-21 16:36:11,359:INFO:Importing untrained model
2023-07-21 16:36:11,364:INFO:Ridge Classifier Imported successfully
2023-07-21 16:36:11,371:INFO:Starting cross validation
2023-07-21 16:36:11,372:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-21 16:36:19,488:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=6.73579e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-21 16:36:19,511:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=6.80776e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-21 16:36:19,528:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.04126e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-21 16:36:19,645:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=6.24009e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-21 16:36:19,682:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=6.83957e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-21 16:36:19,847:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=6.34317e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-21 16:36:19,912:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.93914e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-21 16:36:20,059:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=6.68793e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-21 16:36:20,250:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-21 16:36:20,260:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-21 16:36:20,281:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-21 16:36:20,402:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-21 16:36:20,451:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-21 16:36:20,586:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-21 16:36:20,650:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-21 16:36:20,766:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-21 16:36:25,165:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=6.89903e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-21 16:36:25,319:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=6.73098e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-21 16:36:25,514:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-21 16:36:25,646:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-21 16:36:26,078:INFO:Calculating mean and std
2023-07-21 16:36:26,079:INFO:Creating metrics dataframe
2023-07-21 16:36:26,153:INFO:Uploading results into container
2023-07-21 16:36:26,154:INFO:Uploading model into container now
2023-07-21 16:36:26,154:INFO:_master_model_container: 6
2023-07-21 16:36:26,154:INFO:_display_container: 2
2023-07-21 16:36:26,154:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=100, solver='auto',
                tol=0.0001)
2023-07-21 16:36:26,154:INFO:create_model() successfully completed......................................
2023-07-21 16:36:26,297:INFO:SubProcess create_model() end ==================================
2023-07-21 16:36:26,298:INFO:Creating metrics dataframe
2023-07-21 16:36:26,322:INFO:Initializing Random Forest Classifier
2023-07-21 16:36:26,323:INFO:Total runtime is 12.845688331127167 minutes
2023-07-21 16:36:26,330:INFO:SubProcess create_model() called ==================================
2023-07-21 16:36:26,332:INFO:Initializing create_model()
2023-07-21 16:36:26,332:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FF57EA6F50>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FE93BF49A0>, model_only=True, return_train_score=False, kwargs={})
2023-07-21 16:36:26,333:INFO:Checking exceptions
2023-07-21 16:36:26,333:INFO:Importing libraries
2023-07-21 16:36:26,333:INFO:Copying training dataset
2023-07-21 16:36:27,767:INFO:Defining folds
2023-07-21 16:36:27,767:INFO:Declaring metric variables
2023-07-21 16:36:27,772:INFO:Importing untrained model
2023-07-21 16:36:27,775:INFO:Random Forest Classifier Imported successfully
2023-07-21 16:36:27,783:INFO:Starting cross validation
2023-07-21 16:36:27,785:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-21 16:55:25,532:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-21 16:55:25,533:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-21 16:55:25,533:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-21 16:55:25,533:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-21 16:55:26,666:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-07-21 16:55:29,744:INFO:PyCaret ClassificationExperiment
2023-07-21 16:55:29,745:INFO:Logging name: clf-default-name
2023-07-21 16:55:29,745:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-07-21 16:55:29,745:INFO:version 3.0.1
2023-07-21 16:55:29,745:INFO:Initializing setup()
2023-07-21 16:55:29,745:INFO:self.USI: bfc8
2023-07-21 16:55:29,745:INFO:self._variable_keys: {'target_param', 'html_param', 'y_test', 'logging_param', 'is_multiclass', 'y_train', 'y', 'idx', 'fold_shuffle_param', 'n_jobs_param', 'X_train', 'pipeline', 'fold_generator', 'log_plots_param', 'gpu_n_jobs_param', 'fix_imbalance', 'USI', 'X_test', '_available_plots', 'gpu_param', 'seed', 'fold_groups_param', 'data', 'exp_id', '_ml_usecase', 'memory', 'X', 'exp_name_log'}
2023-07-21 16:55:29,745:INFO:Checking environment
2023-07-21 16:55:29,745:INFO:python_version: 3.10.0
2023-07-21 16:55:29,745:INFO:python_build: ('default', 'Nov 10 2021 13:20:59')
2023-07-21 16:55:29,745:INFO:machine: AMD64
2023-07-21 16:55:29,745:INFO:platform: Windows-10-10.0.22621-SP0
2023-07-21 16:55:29,745:INFO:Memory: svmem(total=16557899776, available=6133870592, percent=63.0, used=10424029184, free=6133870592)
2023-07-21 16:55:29,745:INFO:Physical Core: 8
2023-07-21 16:55:29,746:INFO:Logical Core: 16
2023-07-21 16:55:29,746:INFO:Checking libraries
2023-07-21 16:55:29,746:INFO:System:
2023-07-21 16:55:29,746:INFO:    python: 3.10.0 | packaged by conda-forge | (default, Nov 10 2021, 13:20:59) [MSC v.1916 64 bit (AMD64)]
2023-07-21 16:55:29,746:INFO:executable: C:\Users\Swapn\anaconda3\envs\tf\python.exe
2023-07-21 16:55:29,746:INFO:   machine: Windows-10-10.0.22621-SP0
2023-07-21 16:55:29,746:INFO:PyCaret required dependencies:
2023-07-21 16:55:29,746:INFO:                 pip: 23.2
2023-07-21 16:55:29,746:INFO:          setuptools: 67.7.2
2023-07-21 16:55:29,746:INFO:             pycaret: 3.0.1
2023-07-21 16:55:29,746:INFO:             IPython: 7.34.0
2023-07-21 16:55:29,746:INFO:          ipywidgets: 7.7.5
2023-07-21 16:55:29,746:INFO:                tqdm: 4.65.0
2023-07-21 16:55:29,746:INFO:               numpy: 1.23.0
2023-07-21 16:55:29,746:INFO:              pandas: 1.5.3
2023-07-21 16:55:29,746:INFO:              jinja2: 3.1.2
2023-07-21 16:55:29,746:INFO:               scipy: 1.10.1
2023-07-21 16:55:29,746:INFO:              joblib: 1.2.0
2023-07-21 16:55:29,746:INFO:             sklearn: 1.2.2
2023-07-21 16:55:29,746:INFO:                pyod: 1.0.9
2023-07-21 16:55:29,746:INFO:            imblearn: 0.10.1
2023-07-21 16:55:29,746:INFO:   category_encoders: 2.6.1
2023-07-21 16:55:29,746:INFO:            lightgbm: 3.3.5
2023-07-21 16:55:29,747:INFO:               numba: 0.57.0
2023-07-21 16:55:29,747:INFO:            requests: 2.30.0
2023-07-21 16:55:29,747:INFO:          matplotlib: 3.7.1
2023-07-21 16:55:29,747:INFO:          scikitplot: 0.3.7
2023-07-21 16:55:29,747:INFO:         yellowbrick: 1.5
2023-07-21 16:55:29,747:INFO:              plotly: 5.14.1
2023-07-21 16:55:29,747:INFO:             kaleido: 0.2.1
2023-07-21 16:55:29,747:INFO:         statsmodels: 0.14.0
2023-07-21 16:55:29,747:INFO:              sktime: 0.17.0
2023-07-21 16:55:29,747:INFO:               tbats: 1.1.3
2023-07-21 16:55:29,747:INFO:            pmdarima: 2.0.3
2023-07-21 16:55:29,747:INFO:              psutil: 5.9.0
2023-07-21 16:55:29,747:INFO:PyCaret optional dependencies:
2023-07-21 16:55:31,514:INFO:                shap: 0.42.1
2023-07-21 16:55:31,515:INFO:           interpret: 0.4.2
2023-07-21 16:55:31,515:INFO:                umap: 0.5.3
2023-07-21 16:55:31,515:INFO:    pandas_profiling: 4.3.2
2023-07-21 16:55:31,515:INFO:  explainerdashboard: 0.4.2.2
2023-07-21 16:55:31,515:INFO:             autoviz: 0.1.730
2023-07-21 16:55:31,515:INFO:           fairlearn: 0.7.0
2023-07-21 16:55:31,515:INFO:             xgboost: 1.7.6
2023-07-21 16:55:31,515:INFO:            catboost: 1.2
2023-07-21 16:55:31,515:INFO:              kmodes: 0.12.2
2023-07-21 16:55:31,515:INFO:             mlxtend: 0.22.0
2023-07-21 16:55:31,515:INFO:       statsforecast: 1.5.0
2023-07-21 16:55:31,515:INFO:        tune_sklearn: 0.4.6
2023-07-21 16:55:31,515:INFO:                 ray: 2.6.0
2023-07-21 16:55:31,515:INFO:            hyperopt: 0.2.7
2023-07-21 16:55:31,515:INFO:              optuna: 3.2.0
2023-07-21 16:55:31,515:INFO:               skopt: 0.9.0
2023-07-21 16:55:31,515:INFO:              mlflow: 1.30.1
2023-07-21 16:55:31,515:INFO:              gradio: 3.38.0
2023-07-21 16:55:31,515:INFO:             fastapi: 0.100.0
2023-07-21 16:55:31,515:INFO:             uvicorn: 0.23.1
2023-07-21 16:55:31,515:INFO:              m2cgen: 0.10.0
2023-07-21 16:55:31,515:INFO:           evidently: 0.2.8
2023-07-21 16:55:31,515:INFO:               fugue: 0.8.5
2023-07-21 16:55:31,515:INFO:           streamlit: Not installed
2023-07-21 16:55:31,515:INFO:             prophet: Not installed
2023-07-21 16:55:31,516:INFO:None
2023-07-21 16:55:31,516:INFO:Set up data.
2023-07-21 16:55:32,471:INFO:Set up train/test split.
2023-07-21 16:55:34,391:INFO:Set up index.
2023-07-21 16:55:34,766:INFO:Set up folding strategy.
2023-07-21 16:55:34,767:INFO:Assigning column types.
2023-07-21 16:55:34,943:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-21 16:55:34,992:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-21 16:55:34,995:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-21 16:55:35,034:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-21 16:55:35,430:INFO:Soft dependency imported: catboost: 1.2
2023-07-21 16:55:35,599:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-21 16:55:35,600:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-21 16:55:35,630:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-21 16:55:35,633:INFO:Soft dependency imported: catboost: 1.2
2023-07-21 16:55:35,634:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-21 16:55:35,682:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-21 16:55:35,712:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-21 16:55:35,715:INFO:Soft dependency imported: catboost: 1.2
2023-07-21 16:55:35,765:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-21 16:55:35,795:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-21 16:55:35,799:INFO:Soft dependency imported: catboost: 1.2
2023-07-21 16:55:35,799:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-07-21 16:55:35,878:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-21 16:55:35,881:INFO:Soft dependency imported: catboost: 1.2
2023-07-21 16:55:35,959:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-21 16:55:35,962:INFO:Soft dependency imported: catboost: 1.2
2023-07-21 16:55:35,965:INFO:Preparing preprocessing pipeline...
2023-07-21 16:55:36,019:INFO:Set up simple imputation.
2023-07-21 16:55:36,425:INFO:Set up encoding of categorical features.
2023-07-21 16:55:36,429:INFO:Set up removing outliers.
2023-07-21 16:55:42,426:INFO:Finished creating preprocessing pipeline.
2023-07-21 16:55:42,433:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Swapn\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['amount', 'oldbalanceOrg',
                                             'newbalanceOrig', 'oldbalanceDest',
                                             'newbalanceDest'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy=...
                 TransformerWrapper(exclude=None, include=['type'],
                                    transformer=OneHotEncoder(cols=['type'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_outliers',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=100,
                                                               threshold=0.05)))],
         verbose=False)
2023-07-21 16:55:42,433:INFO:Creating final display dataframe.
2023-07-21 17:00:26,346:INFO:Setup _display_container:                     Description             Value
0                    Session id               100
1                        Target           isFraud
2                   Target type            Binary
3           Original data shape      (4453834, 7)
4        Transformed data shape     (4297950, 11)
5   Transformed train set shape     (2961799, 11)
6    Transformed test set shape     (1336151, 11)
7              Numeric features                 5
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15              Remove outliers              True
16           Outliers threshold              0.05
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              bfc8
2023-07-21 17:00:26,436:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-21 17:00:26,439:INFO:Soft dependency imported: catboost: 1.2
2023-07-21 17:00:26,521:INFO:Soft dependency imported: xgboost: 1.7.6
2023-07-21 17:00:26,524:INFO:Soft dependency imported: catboost: 1.2
2023-07-21 17:00:26,525:INFO:setup() successfully completed in 297.05s...............
2023-07-21 17:00:26,538:INFO:Initializing compare_models()
2023-07-21 17:00:26,538:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016357D66CE0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000016357D66CE0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-21 17:00:26,538:INFO:Checking exceptions
2023-07-21 17:00:27,001:INFO:Preparing display monitor
2023-07-21 17:00:27,028:INFO:Initializing Logistic Regression
2023-07-21 17:00:27,028:INFO:Total runtime is 0.0 minutes
2023-07-21 17:00:27,032:INFO:SubProcess create_model() called ==================================
2023-07-21 17:00:27,032:INFO:Initializing create_model()
2023-07-21 17:00:27,032:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016357D66CE0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016357D67520>, model_only=True, return_train_score=False, kwargs={})
2023-07-21 17:00:27,032:INFO:Checking exceptions
2023-07-21 17:00:27,033:INFO:Importing libraries
2023-07-21 17:00:27,033:INFO:Copying training dataset
2023-07-21 17:00:28,155:INFO:Defining folds
2023-07-21 17:00:28,155:INFO:Declaring metric variables
2023-07-21 17:00:28,159:INFO:Importing untrained model
2023-07-21 17:00:28,163:INFO:Logistic Regression Imported successfully
2023-07-21 17:00:28,170:INFO:Starting cross validation
2023-07-21 17:00:28,181:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-21 17:01:47,981:INFO:Calculating mean and std
2023-07-21 17:01:47,983:INFO:Creating metrics dataframe
2023-07-21 17:01:48,055:INFO:Uploading results into container
2023-07-21 17:01:48,056:INFO:Uploading model into container now
2023-07-21 17:01:48,057:INFO:_master_model_container: 1
2023-07-21 17:01:48,057:INFO:_display_container: 2
2023-07-21 17:01:48,057:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-21 17:01:48,057:INFO:create_model() successfully completed......................................
2023-07-21 17:01:50,402:INFO:SubProcess create_model() end ==================================
2023-07-21 17:01:50,402:INFO:Creating metrics dataframe
2023-07-21 17:01:50,412:INFO:Initializing K Neighbors Classifier
2023-07-21 17:01:50,412:INFO:Total runtime is 1.3897321581840516 minutes
2023-07-21 17:01:50,416:INFO:SubProcess create_model() called ==================================
2023-07-21 17:01:50,416:INFO:Initializing create_model()
2023-07-21 17:01:50,417:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016357D66CE0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016357D67520>, model_only=True, return_train_score=False, kwargs={})
2023-07-21 17:01:50,417:INFO:Checking exceptions
2023-07-21 17:01:50,417:INFO:Importing libraries
2023-07-21 17:01:50,417:INFO:Copying training dataset
2023-07-21 17:01:51,563:INFO:Defining folds
2023-07-21 17:01:51,564:INFO:Declaring metric variables
2023-07-21 17:01:51,567:INFO:Importing untrained model
2023-07-21 17:01:51,572:INFO:K Neighbors Classifier Imported successfully
2023-07-21 17:01:51,579:INFO:Starting cross validation
2023-07-21 17:01:51,590:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-21 17:02:39,372:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 17:02:40,200:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 17:02:51,593:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 17:02:57,215:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-21 17:03:11,750:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-21 17:03:11,915:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-21 17:03:41,469:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-21 17:04:04,501:INFO:Calculating mean and std
2023-07-21 17:04:04,503:INFO:Creating metrics dataframe
2023-07-21 17:04:04,562:INFO:Uploading results into container
2023-07-21 17:04:04,563:INFO:Uploading model into container now
2023-07-21 17:04:04,563:INFO:_master_model_container: 2
2023-07-21 17:04:04,564:INFO:_display_container: 2
2023-07-21 17:04:04,564:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-07-21 17:04:04,564:INFO:create_model() successfully completed......................................
2023-07-21 17:04:04,688:INFO:SubProcess create_model() end ==================================
2023-07-21 17:04:04,689:INFO:Creating metrics dataframe
2023-07-21 17:04:04,702:INFO:Initializing Naive Bayes
2023-07-21 17:04:04,702:INFO:Total runtime is 3.6279022097587585 minutes
2023-07-21 17:04:04,706:INFO:SubProcess create_model() called ==================================
2023-07-21 17:04:04,706:INFO:Initializing create_model()
2023-07-21 17:04:04,706:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016357D66CE0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016357D67520>, model_only=True, return_train_score=False, kwargs={})
2023-07-21 17:04:04,706:INFO:Checking exceptions
2023-07-21 17:04:04,707:INFO:Importing libraries
2023-07-21 17:04:04,707:INFO:Copying training dataset
2023-07-21 17:04:05,857:INFO:Defining folds
2023-07-21 17:04:05,857:INFO:Declaring metric variables
2023-07-21 17:04:05,861:INFO:Importing untrained model
2023-07-21 17:04:05,865:INFO:Naive Bayes Imported successfully
2023-07-21 17:04:05,872:INFO:Starting cross validation
2023-07-21 17:04:05,882:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-21 17:04:24,003:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 17:04:24,089:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 17:04:24,190:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 17:04:24,213:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 17:07:53,254:INFO:Calculating mean and std
2023-07-21 17:07:53,255:INFO:Creating metrics dataframe
2023-07-21 17:07:53,318:INFO:Uploading results into container
2023-07-21 17:07:53,319:INFO:Uploading model into container now
2023-07-21 17:07:53,319:INFO:_master_model_container: 3
2023-07-21 17:07:53,319:INFO:_display_container: 2
2023-07-21 17:07:53,319:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-21 17:07:53,320:INFO:create_model() successfully completed......................................
2023-07-21 17:07:53,439:INFO:SubProcess create_model() end ==================================
2023-07-21 17:07:53,439:INFO:Creating metrics dataframe
2023-07-21 17:07:53,448:INFO:Initializing Decision Tree Classifier
2023-07-21 17:07:53,448:INFO:Total runtime is 7.4403398076693215 minutes
2023-07-21 17:07:53,453:INFO:SubProcess create_model() called ==================================
2023-07-21 17:07:53,453:INFO:Initializing create_model()
2023-07-21 17:07:53,453:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016357D66CE0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016357D67520>, model_only=True, return_train_score=False, kwargs={})
2023-07-21 17:07:53,453:INFO:Checking exceptions
2023-07-21 17:07:53,453:INFO:Importing libraries
2023-07-21 17:07:53,453:INFO:Copying training dataset
2023-07-21 17:07:54,609:INFO:Defining folds
2023-07-21 17:07:54,609:INFO:Declaring metric variables
2023-07-21 17:07:54,613:INFO:Importing untrained model
2023-07-21 17:07:54,617:INFO:Decision Tree Classifier Imported successfully
2023-07-21 17:07:54,626:INFO:Starting cross validation
2023-07-21 17:07:54,636:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-21 17:08:14,217:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 17:08:14,612:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 17:08:14,664:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 17:08:14,751:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-07-21 17:12:12,487:INFO:Calculating mean and std
2023-07-21 17:12:12,488:INFO:Creating metrics dataframe
2023-07-21 17:12:12,556:INFO:Uploading results into container
2023-07-21 17:12:12,557:INFO:Uploading model into container now
2023-07-21 17:12:12,557:INFO:_master_model_container: 4
2023-07-21 17:12:12,557:INFO:_display_container: 2
2023-07-21 17:12:12,558:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=100, splitter='best')
2023-07-21 17:12:12,558:INFO:create_model() successfully completed......................................
2023-07-21 17:12:12,680:INFO:SubProcess create_model() end ==================================
2023-07-21 17:12:12,680:INFO:Creating metrics dataframe
2023-07-21 17:12:12,695:INFO:Initializing SVM - Linear Kernel
2023-07-21 17:12:12,695:INFO:Total runtime is 11.761119198799133 minutes
2023-07-21 17:12:12,699:INFO:SubProcess create_model() called ==================================
2023-07-21 17:12:12,699:INFO:Initializing create_model()
2023-07-21 17:12:12,699:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016357D66CE0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016357D67520>, model_only=True, return_train_score=False, kwargs={})
2023-07-21 17:12:12,699:INFO:Checking exceptions
2023-07-21 17:12:12,699:INFO:Importing libraries
2023-07-21 17:12:12,699:INFO:Copying training dataset
2023-07-21 17:12:13,860:INFO:Defining folds
2023-07-21 17:12:13,860:INFO:Declaring metric variables
2023-07-21 17:12:13,865:INFO:Importing untrained model
2023-07-21 17:12:13,870:INFO:SVM - Linear Kernel Imported successfully
2023-07-21 17:12:13,879:INFO:Starting cross validation
2023-07-21 17:12:13,891:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-21 17:13:09,009:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-21 17:13:09,031:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-21 17:13:12,244:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-21 17:13:15,573:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-21 17:13:16,115:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-21 17:13:18,374:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-21 17:13:20,929:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-21 17:13:27,179:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-21 17:13:28,704:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-21 17:13:40,688:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-21 17:13:41,085:INFO:Calculating mean and std
2023-07-21 17:13:41,088:INFO:Creating metrics dataframe
2023-07-21 17:13:41,156:INFO:Uploading results into container
2023-07-21 17:13:41,157:INFO:Uploading model into container now
2023-07-21 17:13:41,157:INFO:_master_model_container: 5
2023-07-21 17:13:41,157:INFO:_display_container: 2
2023-07-21 17:13:41,158:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=100, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-21 17:13:41,158:INFO:create_model() successfully completed......................................
2023-07-21 17:13:41,287:INFO:SubProcess create_model() end ==================================
2023-07-21 17:13:41,287:INFO:Creating metrics dataframe
2023-07-21 17:13:41,300:INFO:Initializing Ridge Classifier
2023-07-21 17:13:41,301:INFO:Total runtime is 13.237876494725544 minutes
2023-07-21 17:13:41,304:INFO:SubProcess create_model() called ==================================
2023-07-21 17:13:41,304:INFO:Initializing create_model()
2023-07-21 17:13:41,304:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016357D66CE0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016357D67520>, model_only=True, return_train_score=False, kwargs={})
2023-07-21 17:13:41,305:INFO:Checking exceptions
2023-07-21 17:13:41,305:INFO:Importing libraries
2023-07-21 17:13:41,305:INFO:Copying training dataset
2023-07-21 17:13:42,457:INFO:Defining folds
2023-07-21 17:13:42,457:INFO:Declaring metric variables
2023-07-21 17:13:42,461:INFO:Importing untrained model
2023-07-21 17:13:42,466:INFO:Ridge Classifier Imported successfully
2023-07-21 17:13:42,474:INFO:Starting cross validation
2023-07-21 17:13:42,485:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-21 17:13:49,228:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=6.73579e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-21 17:13:49,312:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=6.80776e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-21 17:13:49,415:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.04126e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-21 17:13:49,500:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=6.24009e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-21 17:13:49,595:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=6.83957e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-21 17:13:49,795:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=6.68793e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-21 17:13:49,795:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=6.34317e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-21 17:13:49,824:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.93914e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-21 17:13:49,906:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-21 17:13:50,001:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-21 17:13:50,095:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-21 17:13:50,205:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-21 17:13:50,335:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-21 17:13:50,484:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-21 17:13:50,539:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-21 17:13:50,662:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-21 17:13:54,480:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=6.73098e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-21 17:13:54,506:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=6.89903e-20): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-07-21 17:13:54,743:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-21 17:13:54,776:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-21 17:13:55,238:INFO:Calculating mean and std
2023-07-21 17:13:55,239:INFO:Creating metrics dataframe
2023-07-21 17:13:55,312:INFO:Uploading results into container
2023-07-21 17:13:55,313:INFO:Uploading model into container now
2023-07-21 17:13:55,314:INFO:_master_model_container: 6
2023-07-21 17:13:55,314:INFO:_display_container: 2
2023-07-21 17:13:55,314:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=100, solver='auto',
                tol=0.0001)
2023-07-21 17:13:55,314:INFO:create_model() successfully completed......................................
2023-07-21 17:13:55,454:INFO:SubProcess create_model() end ==================================
2023-07-21 17:13:55,455:INFO:Creating metrics dataframe
2023-07-21 17:13:55,476:INFO:Initializing Random Forest Classifier
2023-07-21 17:13:55,476:INFO:Total runtime is 13.474126950899759 minutes
2023-07-21 17:13:55,483:INFO:SubProcess create_model() called ==================================
2023-07-21 17:13:55,484:INFO:Initializing create_model()
2023-07-21 17:13:55,484:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016357D66CE0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016357D67520>, model_only=True, return_train_score=False, kwargs={})
2023-07-21 17:13:55,484:INFO:Checking exceptions
2023-07-21 17:13:55,484:INFO:Importing libraries
2023-07-21 17:13:55,484:INFO:Copying training dataset
2023-07-21 17:13:56,787:INFO:Defining folds
2023-07-21 17:13:56,787:INFO:Declaring metric variables
2023-07-21 17:13:56,791:INFO:Importing untrained model
2023-07-21 17:13:56,796:INFO:Random Forest Classifier Imported successfully
2023-07-21 17:13:56,803:INFO:Starting cross validation
2023-07-21 17:13:56,813:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-21 17:27:21,710:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 9.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 17:27:21,742:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 9.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 17:27:21,740:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 9.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 17:27:21,746:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 9.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 17:27:21,909:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 9.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 17:27:23,680:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 17:27:23,936:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.46s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 17:27:25,746:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-21 17:27:26,548:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-21 17:27:26,576:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 3.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 17:27:30,181:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-21 17:27:33,983:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 17:27:37,330:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 17:27:39,738:INFO:Calculating mean and std
2023-07-21 17:27:39,796:INFO:Creating metrics dataframe
2023-07-21 17:27:39,993:INFO:Uploading results into container
2023-07-21 17:27:39,998:INFO:Uploading model into container now
2023-07-21 17:27:40,006:INFO:_master_model_container: 7
2023-07-21 17:27:40,006:INFO:_display_container: 2
2023-07-21 17:27:40,017:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=100, verbose=0, warm_start=False)
2023-07-21 17:27:40,018:INFO:create_model() successfully completed......................................
2023-07-21 17:27:40,727:INFO:SubProcess create_model() end ==================================
2023-07-21 17:27:40,727:INFO:Creating metrics dataframe
2023-07-21 17:27:40,749:INFO:Initializing Quadratic Discriminant Analysis
2023-07-21 17:27:40,749:INFO:Total runtime is 27.228681735197704 minutes
2023-07-21 17:27:40,754:INFO:SubProcess create_model() called ==================================
2023-07-21 17:27:40,754:INFO:Initializing create_model()
2023-07-21 17:27:40,754:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016357D66CE0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016357D67520>, model_only=True, return_train_score=False, kwargs={})
2023-07-21 17:27:40,754:INFO:Checking exceptions
2023-07-21 17:27:40,755:INFO:Importing libraries
2023-07-21 17:27:40,755:INFO:Copying training dataset
2023-07-21 17:27:43,534:INFO:Defining folds
2023-07-21 17:27:43,535:INFO:Declaring metric variables
2023-07-21 17:27:43,541:INFO:Importing untrained model
2023-07-21 17:27:43,549:INFO:Quadratic Discriminant Analysis Imported successfully
2023-07-21 17:27:43,561:INFO:Starting cross validation
2023-07-21 17:27:43,581:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-21 17:28:17,600:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-21 17:28:18,326:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-21 17:28:18,927:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-21 17:28:20,037:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-21 17:28:20,084:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-21 17:28:20,087:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-21 17:28:20,097:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-21 17:28:20,116:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-21 17:28:20,175:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-21 17:28:20,206:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-21 17:28:20,213:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.38s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 17:28:20,217:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 17:28:20,235:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 17:28:20,888:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 17:28:20,889:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 17:28:20,894:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 17:28:20,895:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 17:28:20,995:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 17:28:20,996:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 17:28:21,012:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-21 17:28:21,027:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-21 17:28:21,070:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 17:28:21,070:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 17:28:21,072:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 17:28:21,085:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-21 17:28:21,157:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-21 17:28:21,320:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 17:28:21,320:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 17:28:21,450:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-21 17:28:21,461:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 17:28:21,462:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 17:28:21,466:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 17:28:21,468:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 17:28:21,468:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 17:28:21,468:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 17:28:21,522:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 17:28:21,522:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 17:28:21,527:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 17:28:21,529:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 17:28:21,591:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-21 17:28:21,591:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-21 17:28:21,602:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-21 17:28:21,622:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 17:28:21,623:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 17:28:21,636:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-21 17:28:21,641:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-21 17:28:21,718:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-21 17:28:21,719:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-21 17:28:21,719:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-21 17:28:21,735:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-21 17:28:21,792:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-21 17:28:21,853:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 17:28:21,854:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 17:28:21,914:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 17:28:21,915:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 17:28:21,954:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-21 17:28:21,977:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 17:28:21,978:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 17:28:21,979:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 17:28:21,980:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 17:28:22,014:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-21 17:28:22,036:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-21 17:28:22,066:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-21 17:28:22,067:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-21 17:28:22,150:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 17:28:22,150:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-21 17:28:22,151:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 17:28:22,152:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-21 17:28:22,260:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-21 17:28:22,339:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 17:28:22,340:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 17:28:22,419:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-21 17:28:22,501:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-21 17:28:22,569:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 17:28:22,569:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-07-21 17:28:22,641:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-07-21 17:28:22,708:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-07-21 17:28:23,732:INFO:Calculating mean and std
2023-07-21 17:28:23,769:INFO:Creating metrics dataframe
2023-07-21 17:28:23,892:INFO:Uploading results into container
2023-07-21 17:28:23,895:INFO:Uploading model into container now
2023-07-21 17:28:23,899:INFO:_master_model_container: 8
2023-07-21 17:28:23,900:INFO:_display_container: 2
2023-07-21 17:28:23,903:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-07-21 17:28:23,903:INFO:create_model() successfully completed......................................
2023-07-21 17:28:24,393:INFO:SubProcess create_model() end ==================================
2023-07-21 17:28:24,393:INFO:Creating metrics dataframe
2023-07-21 17:28:24,413:INFO:Initializing Ada Boost Classifier
2023-07-21 17:28:24,413:INFO:Total runtime is 27.95642062028249 minutes
2023-07-21 17:28:24,417:INFO:SubProcess create_model() called ==================================
2023-07-21 17:28:24,418:INFO:Initializing create_model()
2023-07-21 17:28:24,418:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016357D66CE0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016357D67520>, model_only=True, return_train_score=False, kwargs={})
2023-07-21 17:28:24,418:INFO:Checking exceptions
2023-07-21 17:28:24,418:INFO:Importing libraries
2023-07-21 17:28:24,419:INFO:Copying training dataset
2023-07-21 17:28:26,039:INFO:Defining folds
2023-07-21 17:28:26,039:INFO:Declaring metric variables
2023-07-21 17:28:26,044:INFO:Importing untrained model
2023-07-21 17:28:26,048:INFO:Ada Boost Classifier Imported successfully
2023-07-21 17:28:26,056:INFO:Starting cross validation
2023-07-21 17:28:26,075:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-21 17:33:59,107:INFO:Calculating mean and std
2023-07-21 17:33:59,109:INFO:Creating metrics dataframe
2023-07-21 17:33:59,184:INFO:Uploading results into container
2023-07-21 17:33:59,184:INFO:Uploading model into container now
2023-07-21 17:33:59,185:INFO:_master_model_container: 9
2023-07-21 17:33:59,185:INFO:_display_container: 2
2023-07-21 17:33:59,185:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=100)
2023-07-21 17:33:59,185:INFO:create_model() successfully completed......................................
2023-07-21 17:33:59,305:INFO:SubProcess create_model() end ==================================
2023-07-21 17:33:59,305:INFO:Creating metrics dataframe
2023-07-21 17:33:59,321:INFO:Initializing Gradient Boosting Classifier
2023-07-21 17:33:59,321:INFO:Total runtime is 33.53821907440821 minutes
2023-07-21 17:33:59,325:INFO:SubProcess create_model() called ==================================
2023-07-21 17:33:59,326:INFO:Initializing create_model()
2023-07-21 17:33:59,326:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016357D66CE0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016357D67520>, model_only=True, return_train_score=False, kwargs={})
2023-07-21 17:33:59,326:INFO:Checking exceptions
2023-07-21 17:33:59,326:INFO:Importing libraries
2023-07-21 17:33:59,326:INFO:Copying training dataset
2023-07-21 17:34:00,518:INFO:Defining folds
2023-07-21 17:34:00,519:INFO:Declaring metric variables
2023-07-21 17:34:00,523:INFO:Importing untrained model
2023-07-21 17:34:00,527:INFO:Gradient Boosting Classifier Imported successfully
2023-07-21 17:34:00,535:INFO:Starting cross validation
2023-07-21 17:34:00,547:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-21 17:55:30,668:INFO:Calculating mean and std
2023-07-21 17:55:30,670:INFO:Creating metrics dataframe
2023-07-21 17:55:30,785:INFO:Uploading results into container
2023-07-21 17:55:30,786:INFO:Uploading model into container now
2023-07-21 17:55:30,787:INFO:_master_model_container: 10
2023-07-21 17:55:30,787:INFO:_display_container: 2
2023-07-21 17:55:30,787:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=100, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-21 17:55:30,787:INFO:create_model() successfully completed......................................
2023-07-21 17:55:30,916:INFO:SubProcess create_model() end ==================================
2023-07-21 17:55:30,917:INFO:Creating metrics dataframe
2023-07-21 17:55:30,932:INFO:Initializing Linear Discriminant Analysis
2023-07-21 17:55:30,932:INFO:Total runtime is 55.06506691376368 minutes
2023-07-21 17:55:30,936:INFO:SubProcess create_model() called ==================================
2023-07-21 17:55:30,937:INFO:Initializing create_model()
2023-07-21 17:55:30,937:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016357D66CE0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016357D67520>, model_only=True, return_train_score=False, kwargs={})
2023-07-21 17:55:30,937:INFO:Checking exceptions
2023-07-21 17:55:30,937:INFO:Importing libraries
2023-07-21 17:55:30,937:INFO:Copying training dataset
2023-07-21 17:55:32,128:INFO:Defining folds
2023-07-21 17:55:32,128:INFO:Declaring metric variables
2023-07-21 17:55:32,132:INFO:Importing untrained model
2023-07-21 17:55:32,136:INFO:Linear Discriminant Analysis Imported successfully
2023-07-21 17:55:32,145:INFO:Starting cross validation
2023-07-21 17:55:32,156:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-21 17:55:49,984:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 17:55:51,996:INFO:Calculating mean and std
2023-07-21 17:55:52,002:INFO:Creating metrics dataframe
2023-07-21 17:55:52,102:INFO:Uploading results into container
2023-07-21 17:55:52,104:INFO:Uploading model into container now
2023-07-21 17:55:52,106:INFO:_master_model_container: 11
2023-07-21 17:55:52,106:INFO:_display_container: 2
2023-07-21 17:55:52,108:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-07-21 17:55:52,108:INFO:create_model() successfully completed......................................
2023-07-21 17:55:52,411:INFO:SubProcess create_model() end ==================================
2023-07-21 17:55:52,411:INFO:Creating metrics dataframe
2023-07-21 17:55:52,427:INFO:Initializing Extra Trees Classifier
2023-07-21 17:55:52,427:INFO:Total runtime is 55.42331397533417 minutes
2023-07-21 17:55:52,432:INFO:SubProcess create_model() called ==================================
2023-07-21 17:55:52,433:INFO:Initializing create_model()
2023-07-21 17:55:52,433:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016357D66CE0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016357D67520>, model_only=True, return_train_score=False, kwargs={})
2023-07-21 17:55:52,433:INFO:Checking exceptions
2023-07-21 17:55:52,433:INFO:Importing libraries
2023-07-21 17:55:52,433:INFO:Copying training dataset
2023-07-21 17:55:53,959:INFO:Defining folds
2023-07-21 17:55:53,959:INFO:Declaring metric variables
2023-07-21 17:55:53,964:INFO:Importing untrained model
2023-07-21 17:55:53,969:INFO:Extra Trees Classifier Imported successfully
2023-07-21 17:55:53,977:INFO:Starting cross validation
2023-07-21 17:55:53,992:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-21 17:58:38,087:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 3.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 17:58:38,668:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 17:58:40,402:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 17:58:40,736:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-21 17:58:41,288:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 17:58:43,156:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-21 17:58:44,248:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.49s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-21 17:58:45,797:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-07-21 18:02:30,439:INFO:Calculating mean and std
2023-07-21 18:02:30,441:INFO:Creating metrics dataframe
2023-07-21 18:02:30,528:INFO:Uploading results into container
2023-07-21 18:02:30,529:INFO:Uploading model into container now
2023-07-21 18:02:30,529:INFO:_master_model_container: 12
2023-07-21 18:02:30,529:INFO:_display_container: 2
2023-07-21 18:02:30,530:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=100, verbose=0, warm_start=False)
2023-07-21 18:02:30,530:INFO:create_model() successfully completed......................................
2023-07-21 18:02:30,712:INFO:SubProcess create_model() end ==================================
2023-07-21 18:02:30,712:INFO:Creating metrics dataframe
2023-07-21 18:02:30,728:INFO:Initializing Extreme Gradient Boosting
2023-07-21 18:02:30,728:INFO:Total runtime is 62.06166768868764 minutes
2023-07-21 18:02:30,732:INFO:SubProcess create_model() called ==================================
2023-07-21 18:02:30,733:INFO:Initializing create_model()
2023-07-21 18:02:30,733:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016357D66CE0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016357D67520>, model_only=True, return_train_score=False, kwargs={})
2023-07-21 18:02:30,733:INFO:Checking exceptions
2023-07-21 18:02:30,733:INFO:Importing libraries
2023-07-21 18:02:30,733:INFO:Copying training dataset
2023-07-21 18:02:32,015:INFO:Defining folds
2023-07-21 18:02:32,016:INFO:Declaring metric variables
2023-07-21 18:02:32,019:INFO:Importing untrained model
2023-07-21 18:02:32,024:INFO:Extreme Gradient Boosting Imported successfully
2023-07-21 18:02:32,031:INFO:Starting cross validation
2023-07-21 18:02:32,045:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-21 18:14:37,939:INFO:Calculating mean and std
2023-07-21 18:14:37,941:INFO:Creating metrics dataframe
2023-07-21 18:14:38,025:INFO:Uploading results into container
2023-07-21 18:14:38,025:INFO:Uploading model into container now
2023-07-21 18:14:38,026:INFO:_master_model_container: 13
2023-07-21 18:14:38,026:INFO:_display_container: 2
2023-07-21 18:14:38,027:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-07-21 18:14:38,027:INFO:create_model() successfully completed......................................
2023-07-21 18:14:38,146:INFO:SubProcess create_model() end ==================================
2023-07-21 18:14:38,147:INFO:Creating metrics dataframe
2023-07-21 18:14:38,163:INFO:Initializing Light Gradient Boosting Machine
2023-07-21 18:14:38,163:INFO:Total runtime is 74.18559004863103 minutes
2023-07-21 18:14:38,167:INFO:SubProcess create_model() called ==================================
2023-07-21 18:14:38,168:INFO:Initializing create_model()
2023-07-21 18:14:38,168:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016357D66CE0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016357D67520>, model_only=True, return_train_score=False, kwargs={})
2023-07-21 18:14:38,168:INFO:Checking exceptions
2023-07-21 18:14:38,168:INFO:Importing libraries
2023-07-21 18:14:38,168:INFO:Copying training dataset
2023-07-21 18:14:39,369:INFO:Defining folds
2023-07-21 18:14:39,369:INFO:Declaring metric variables
2023-07-21 18:14:39,373:INFO:Importing untrained model
2023-07-21 18:14:39,377:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-21 18:14:39,386:INFO:Starting cross validation
2023-07-21 18:14:39,396:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-21 18:15:29,886:INFO:Calculating mean and std
2023-07-21 18:15:29,888:INFO:Creating metrics dataframe
2023-07-21 18:15:29,973:INFO:Uploading results into container
2023-07-21 18:15:29,974:INFO:Uploading model into container now
2023-07-21 18:15:29,974:INFO:_master_model_container: 14
2023-07-21 18:15:29,974:INFO:_display_container: 2
2023-07-21 18:15:29,975:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=100, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-07-21 18:15:29,975:INFO:create_model() successfully completed......................................
2023-07-21 18:15:30,103:INFO:SubProcess create_model() end ==================================
2023-07-21 18:15:30,103:INFO:Creating metrics dataframe
2023-07-21 18:15:30,119:INFO:Initializing CatBoost Classifier
2023-07-21 18:15:30,120:INFO:Total runtime is 75.05153441031773 minutes
2023-07-21 18:15:30,123:INFO:SubProcess create_model() called ==================================
2023-07-21 18:15:30,124:INFO:Initializing create_model()
2023-07-21 18:15:30,124:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016357D66CE0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016357D67520>, model_only=True, return_train_score=False, kwargs={})
2023-07-21 18:15:30,124:INFO:Checking exceptions
2023-07-21 18:15:30,124:INFO:Importing libraries
2023-07-21 18:15:30,124:INFO:Copying training dataset
2023-07-21 18:15:31,307:INFO:Defining folds
2023-07-21 18:15:31,307:INFO:Declaring metric variables
2023-07-21 18:15:31,311:INFO:Importing untrained model
2023-07-21 18:15:31,324:INFO:CatBoost Classifier Imported successfully
2023-07-21 18:15:31,331:INFO:Starting cross validation
2023-07-21 18:15:31,343:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-21 18:39:09,314:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 18:39:44,888:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 18:39:48,126:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 18:44:40,904:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-21 18:45:25,254:INFO:Calculating mean and std
2023-07-21 18:45:25,256:INFO:Creating metrics dataframe
2023-07-21 18:45:25,350:INFO:Uploading results into container
2023-07-21 18:45:25,351:INFO:Uploading model into container now
2023-07-21 18:45:25,352:INFO:_master_model_container: 15
2023-07-21 18:45:25,352:INFO:_display_container: 2
2023-07-21 18:45:25,352:INFO:<catboost.core.CatBoostClassifier object at 0x00000163555737F0>
2023-07-21 18:45:25,352:INFO:create_model() successfully completed......................................
2023-07-21 18:45:25,540:INFO:SubProcess create_model() end ==================================
2023-07-21 18:45:25,540:INFO:Creating metrics dataframe
2023-07-21 18:45:25,557:INFO:Initializing Dummy Classifier
2023-07-21 18:45:25,557:INFO:Total runtime is 104.97548662424086 minutes
2023-07-21 18:45:25,561:INFO:SubProcess create_model() called ==================================
2023-07-21 18:45:25,562:INFO:Initializing create_model()
2023-07-21 18:45:25,562:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016357D66CE0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016357D67520>, model_only=True, return_train_score=False, kwargs={})
2023-07-21 18:45:25,562:INFO:Checking exceptions
2023-07-21 18:45:25,562:INFO:Importing libraries
2023-07-21 18:45:25,562:INFO:Copying training dataset
2023-07-21 18:45:26,836:INFO:Defining folds
2023-07-21 18:45:26,837:INFO:Declaring metric variables
2023-07-21 18:45:26,841:INFO:Importing untrained model
2023-07-21 18:45:26,845:INFO:Dummy Classifier Imported successfully
2023-07-21 18:45:26,852:INFO:Starting cross validation
2023-07-21 18:45:26,865:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-21 18:45:31,861:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-21 18:45:31,896:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-21 18:45:31,924:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-21 18:45:31,925:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-21 18:45:32,019:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-21 18:45:32,058:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-21 18:45:37,406:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-21 18:45:37,418:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-21 18:45:37,441:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-21 18:45:37,442:WARNING:C:\Users\Swapn\anaconda3\envs\tf\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-21 18:45:37,989:INFO:Calculating mean and std
2023-07-21 18:45:37,990:INFO:Creating metrics dataframe
2023-07-21 18:45:38,080:INFO:Uploading results into container
2023-07-21 18:45:38,081:INFO:Uploading model into container now
2023-07-21 18:45:38,081:INFO:_master_model_container: 16
2023-07-21 18:45:38,081:INFO:_display_container: 2
2023-07-21 18:45:38,082:INFO:DummyClassifier(constant=None, random_state=100, strategy='prior')
2023-07-21 18:45:38,082:INFO:create_model() successfully completed......................................
2023-07-21 18:45:38,205:INFO:SubProcess create_model() end ==================================
2023-07-21 18:45:38,205:INFO:Creating metrics dataframe
2023-07-21 18:45:38,234:INFO:Initializing create_model()
2023-07-21 18:45:38,234:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016357D66CE0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-21 18:45:38,234:INFO:Checking exceptions
2023-07-21 18:45:38,244:INFO:Importing libraries
2023-07-21 18:45:38,244:INFO:Copying training dataset
2023-07-21 18:45:39,410:INFO:Defining folds
2023-07-21 18:45:39,410:INFO:Declaring metric variables
2023-07-21 18:45:39,410:INFO:Importing untrained model
2023-07-21 18:45:39,410:INFO:Declaring custom model
2023-07-21 18:45:39,411:INFO:Logistic Regression Imported successfully
2023-07-21 18:45:39,421:INFO:Cross validation set to False
2023-07-21 18:45:39,421:INFO:Fitting Model
2023-07-21 18:48:15,465:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-21 18:48:15,465:INFO:create_model() successfully completed......................................
2023-07-21 18:48:15,611:INFO:Initializing create_model()
2023-07-21 18:48:15,612:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016357D66CE0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-21 18:48:15,612:INFO:Checking exceptions
2023-07-21 18:48:15,614:INFO:Importing libraries
2023-07-21 18:48:15,615:INFO:Copying training dataset
2023-07-21 18:48:16,797:INFO:Defining folds
2023-07-21 18:48:16,797:INFO:Declaring metric variables
2023-07-21 18:48:16,797:INFO:Importing untrained model
2023-07-21 18:48:16,797:INFO:Declaring custom model
2023-07-21 18:48:16,799:INFO:Extreme Gradient Boosting Imported successfully
2023-07-21 18:48:16,810:INFO:Cross validation set to False
2023-07-21 18:48:16,810:INFO:Fitting Model
2023-07-21 18:50:07,942:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-07-21 18:50:07,943:INFO:create_model() successfully completed......................................
2023-07-21 18:50:08,071:INFO:Initializing create_model()
2023-07-21 18:50:08,071:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016357D66CE0>, estimator=<catboost.core.CatBoostClassifier object at 0x00000163555737F0>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-21 18:50:08,072:INFO:Checking exceptions
2023-07-21 18:50:08,073:INFO:Importing libraries
2023-07-21 18:50:08,074:INFO:Copying training dataset
2023-07-21 18:50:09,240:INFO:Defining folds
2023-07-21 18:50:09,240:INFO:Declaring metric variables
2023-07-21 18:50:09,240:INFO:Importing untrained model
2023-07-21 18:50:09,240:INFO:Declaring custom model
2023-07-21 18:50:09,242:INFO:CatBoost Classifier Imported successfully
2023-07-21 18:50:09,252:INFO:Cross validation set to False
2023-07-21 18:50:09,252:INFO:Fitting Model
2023-07-21 18:54:02,879:INFO:<catboost.core.CatBoostClassifier object at 0x000001638F6874F0>
2023-07-21 18:54:02,879:INFO:create_model() successfully completed......................................
2023-07-21 18:54:03,044:INFO:_master_model_container: 16
2023-07-21 18:54:03,044:INFO:_display_container: 2
2023-07-21 18:54:03,045:INFO:[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), <catboost.core.CatBoostClassifier object at 0x000001638F6874F0>]
2023-07-21 18:54:03,045:INFO:compare_models() successfully completed......................................
2023-07-21 18:54:03,074:INFO:Initializing create_model()
2023-07-21 18:54:03,075:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016357D66CE0>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-21 18:54:03,075:INFO:Checking exceptions
2023-07-21 18:54:03,097:INFO:Importing libraries
2023-07-21 18:54:03,097:INFO:Copying training dataset
2023-07-21 18:54:04,315:INFO:Defining folds
2023-07-21 18:54:04,315:INFO:Declaring metric variables
2023-07-21 18:54:04,319:INFO:Importing untrained model
2023-07-21 18:54:04,323:INFO:Logistic Regression Imported successfully
2023-07-21 18:54:04,330:INFO:Starting cross validation
2023-07-21 18:54:04,341:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-21 18:55:19,029:INFO:Calculating mean and std
2023-07-21 18:55:19,031:INFO:Creating metrics dataframe
2023-07-21 18:55:19,036:INFO:Finalizing model
2023-07-21 18:55:20,461:INFO:Uploading results into container
2023-07-21 18:55:20,462:INFO:Uploading model into container now
2023-07-21 18:55:20,474:INFO:_master_model_container: 17
2023-07-21 18:55:20,475:INFO:_display_container: 3
2023-07-21 18:55:20,475:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-21 18:55:20,475:INFO:create_model() successfully completed......................................
2023-07-21 18:55:20,656:INFO:Initializing plot_model()
2023-07-21 18:55:20,656:INFO:plot_model(plot=learning, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016357D66CE0>, system=True)
2023-07-21 18:55:20,657:INFO:Checking exceptions
2023-07-21 18:55:21,177:INFO:Preloading libraries
2023-07-21 18:55:21,178:INFO:Copying training dataset
2023-07-21 18:55:21,178:INFO:Plot type: learning
2023-07-21 18:57:44,484:INFO:Fitting Model
2023-07-21 19:14:21,870:INFO:Visual Rendered Successfully
2023-07-21 19:14:22,021:INFO:plot_model() successfully completed......................................
2023-07-21 19:14:22,039:INFO:Initializing plot_model()
2023-07-21 19:14:22,039:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016357D66CE0>, system=True)
2023-07-21 19:14:22,039:INFO:Checking exceptions
2023-07-21 19:14:22,475:INFO:Preloading libraries
2023-07-21 19:14:22,476:INFO:Copying training dataset
2023-07-21 19:14:22,476:INFO:Plot type: auc
2023-07-21 19:14:25,593:INFO:Fitting Model
2023-07-21 19:14:25,657:INFO:Scoring test/hold-out set
2023-07-21 19:14:26,841:INFO:Visual Rendered Successfully
2023-07-21 19:14:26,977:INFO:plot_model() successfully completed......................................
2023-07-21 19:14:26,988:INFO:Initializing plot_model()
2023-07-21 19:14:26,988:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs={'percent': True}, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016357D66CE0>, system=True)
2023-07-21 19:14:26,988:INFO:Checking exceptions
2023-07-21 19:14:27,429:INFO:Preloading libraries
2023-07-21 19:14:27,429:INFO:Copying training dataset
2023-07-21 19:14:27,429:INFO:Plot type: confusion_matrix
2023-07-21 19:14:30,634:INFO:Fitting Model
2023-07-21 19:14:30,667:INFO:Scoring test/hold-out set
2023-07-21 19:14:31,093:INFO:Visual Rendered Successfully
2023-07-21 19:14:31,232:INFO:plot_model() successfully completed......................................
2023-07-21 19:14:31,246:INFO:Initializing plot_model()
2023-07-21 19:14:31,247:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016357D66CE0>, system=True)
2023-07-21 19:14:31,247:INFO:Checking exceptions
2023-07-21 19:14:31,668:INFO:Preloading libraries
2023-07-21 19:14:31,668:INFO:Copying training dataset
2023-07-21 19:14:31,668:INFO:Plot type: error
2023-07-21 19:14:34,791:INFO:Fitting Model
2023-07-21 19:14:34,823:INFO:Scoring test/hold-out set
2023-07-21 19:14:35,358:INFO:Visual Rendered Successfully
2023-07-21 19:14:35,496:INFO:plot_model() successfully completed......................................
2023-07-21 19:14:35,517:INFO:Initializing plot_model()
2023-07-21 19:14:35,517:INFO:plot_model(plot=class_report, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016357D66CE0>, system=True)
2023-07-21 19:14:35,517:INFO:Checking exceptions
2023-07-21 19:14:35,940:INFO:Preloading libraries
2023-07-21 19:14:35,940:INFO:Copying training dataset
2023-07-21 19:14:35,940:INFO:Plot type: class_report
2023-07-21 19:14:39,096:INFO:Fitting Model
2023-07-21 19:14:39,130:INFO:Scoring test/hold-out set
2023-07-21 19:14:39,839:INFO:Visual Rendered Successfully
2023-07-21 19:14:39,976:INFO:plot_model() successfully completed......................................
2023-07-21 19:14:39,988:INFO:Initializing plot_model()
2023-07-21 19:14:39,989:INFO:plot_model(plot=boundary, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016357D66CE0>, system=True)
2023-07-21 19:14:39,989:INFO:Checking exceptions
2023-07-21 19:14:40,409:INFO:Preloading libraries
2023-07-21 19:14:40,409:INFO:Copying training dataset
2023-07-21 19:14:40,409:INFO:Plot type: boundary
2023-07-21 19:14:42,105:INFO:Fitting StandardScaler()
2023-07-21 19:14:42,806:INFO:Fitting PCA()
2023-07-21 19:14:51,018:INFO:Fitting Model
2023-07-21 19:15:35,460:INFO:Visual Rendered Successfully
2023-07-21 19:15:35,672:INFO:plot_model() successfully completed......................................
2023-07-21 19:15:35,683:INFO:Initializing evaluate_model()
2023-07-21 19:15:35,683:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016357D66CE0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-07-21 19:15:36,148:INFO:Initializing plot_model()
2023-07-21 19:15:36,149:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016357D66CE0>, system=True)
2023-07-21 19:15:36,149:INFO:Checking exceptions
2023-07-21 19:15:36,638:INFO:Preloading libraries
2023-07-21 19:15:36,639:INFO:Copying training dataset
2023-07-21 19:15:36,639:INFO:Plot type: pipeline
2023-07-21 19:15:36,909:INFO:Visual Rendered Successfully
2023-07-21 19:15:37,049:INFO:plot_model() successfully completed......................................
2023-07-21 19:15:37,070:INFO:Initializing predict_model()
2023-07-21 19:15:37,070:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016357D66CE0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000162FF6AC8B0>)
2023-07-21 19:15:37,071:INFO:Checking exceptions
2023-07-21 19:15:37,071:INFO:Preloading libraries
2023-07-21 19:15:41,331:INFO:Initializing predict_model()
2023-07-21 19:15:41,331:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016357D66CE0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000162FF6ACDC0>)
2023-07-21 19:15:41,331:INFO:Checking exceptions
2023-07-21 19:15:41,331:INFO:Preloading libraries
2023-07-21 19:15:41,334:INFO:Set up data.
2023-07-21 19:15:42,178:INFO:Set up index.
